{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate evaluation triplets from studies \n",
    "\n",
    "\n",
    "1. parse document \n",
    "2. extract claims that are accosiated with refereces via LLM and save in json with referenced paper as name\n",
    "3. generate topic of claim like (sustanability, business, money, or something like that)\n",
    "4. repeat step 1-3 for multiple reports from diverse topics that care be releated tho like (genai, sustability, business report)\n",
    "5. bundle 2-3 claims together from multiple related documents into one claim via LLM\n",
    "6. generate question for bundled claim \n",
    "7. store question, claim and added references in json objects\n",
    "8. repeat step 6 and 7\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = OpenAI(model=\"gpt-4\")\n",
    "\n",
    "def parse_pdf(file_path: str) -> str:\n",
    "    \"\"\"Parse PDF content into a single text string.\"\"\"\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def extract_claims_with_references(document: str) -> List[Dict]:\n",
    "    \"\"\"Extract claims and associated references using LLM.\"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"document\"],\n",
    "        template=\"Extract claims from the document that are associated with references. Return as JSON format: \"\n",
    "                 \"[{'claim': '...', 'references': ['ref1', 'ref2', ...]}]. Document: {document}\"\n",
    "    )\n",
    "    response = llm(prompt.format(document=document))\n",
    "    return json.loads(response)\n",
    "\n",
    "def generate_topic(claim: str) -> str:\n",
    "    \"\"\"Generate a topic for a claim.\"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"claim\"],\n",
    "        template=\"Identify the topic of the claim (e.g., sustainability, business, money, etc.). Claim: {claim}\"\n",
    "    )\n",
    "    response = llm(prompt.format(claim=claim))\n",
    "    return response.strip()\n",
    "\n",
    "def bundle_claims(claims: List[Dict]) -> Dict:\n",
    "    \"\"\"Bundle 2-3 claims together into one comprehensive claim.\"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"claims\"],\n",
    "        template=\"Combine the following claims into one coherent claim. \"\n",
    "                 \"Claims: {claims}. Return as JSON format: {'claim': '...', 'references': [...]}.\"\n",
    "    )\n",
    "    response = llm(prompt.format(claims=claims))\n",
    "    return json.loads(response)\n",
    "\n",
    "def generate_question(claim: str) -> str:\n",
    "    \"\"\"Generate a question for a bundled claim.\"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"claim\"],\n",
    "        template=\"Generate a question that aligns with this claim. Claim: {claim}\"\n",
    "    )\n",
    "    response = llm(prompt.format(claim=claim))\n",
    "    return response.strip()\n",
    "\n",
    "def process_reports(directory: str) -> List[Dict]:\n",
    "    \"\"\"Process multiple reports to generate evaluation triplets.\"\"\"\n",
    "    evaluation_triplets = []\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            document = parse_pdf(file_path)\n",
    "            claims = extract_claims_with_references(document)\n",
    "\n",
    "            for claim_data in claims:\n",
    "                claim_data['topic'] = generate_topic(claim_data['claim'])\n",
    "            \n",
    "            # Store the claims for this document\n",
    "            with open(f\"{file}_claims.json\", \"w\") as f:\n",
    "                json.dump(claims, f, indent=4)\n",
    "    \n",
    "    # Bundle claims and generate questions\n",
    "    all_claims = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\"_claims.json\"):\n",
    "            with open(os.path.join(directory, file), \"r\") as f:\n",
    "                all_claims.extend(json.load(f))\n",
    "    \n",
    "    # Group claims by topic\n",
    "    grouped_claims = {}\n",
    "    for claim in all_claims:\n",
    "        topic = claim['topic']\n",
    "        grouped_claims.setdefault(topic, []).append(claim)\n",
    "    \n",
    "    for topic, claims in grouped_claims.items():\n",
    "        for i in range(0, len(claims), 2):  # Bundling 2-3 claims together\n",
    "            claim_subset = claims[i:i+3]\n",
    "            if len(claim_subset) > 1:\n",
    "                bundled_claim = bundle_claims(claim_subset)\n",
    "                question = generate_question(bundled_claim['claim'])\n",
    "                evaluation_triplets.append({\n",
    "                    \"question\": question,\n",
    "                    \"claim\": bundled_claim['claim'],\n",
    "                    \"references\": bundled_claim['references']\n",
    "                })\n",
    "    \n",
    "    # Save evaluation triplets\n",
    "    with open(\"evaluation_triplets.json\", \"w\") as f:\n",
    "        json.dump(evaluation_triplets, f, indent=4)\n",
    "    \n",
    "    return evaluation_triplets\n",
    "\n",
    "# Directory containing your reports\n",
    "reports_directory = \"./reports\"\n",
    "triplets = process_reports(reports_directory)\n",
    "print(\"Evaluation triplets generated and saved to 'evaluation_triplets.json'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
