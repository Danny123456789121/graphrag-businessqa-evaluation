{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.schema import Document\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import tiktoken\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv(override=True)\n",
    "\n",
    "data_dir = \"input_big_context/\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI( model=\"gemini-1.5-flash\", temperature=0, max_retries=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse PDF Documents to Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting bcg-accelerating-climate-action-with-ai-nov-2023-rev.pdf to markdown\n",
      "Started parsing the file under job_id b236c775-efff-4ce1-8a68-d36df9f798da\n",
      "..Saving markdown to input_big_context/bcg-accelerating-climate-action-with-ai-nov-2023-rev.md\n",
      "Successfully converted bcg-accelerating-climate-action-with-ai-nov-2023-rev.pdf\n",
      "Converting SAP Integrated Report 2023.pdf to markdown\n",
      "Started parsing the file under job_id fc2a1afb-fdba-489a-b5eb-ce9893c1fe7a\n",
      "...Saving markdown to input_big_context/SAP Integrated Report 2023.md\n",
      "Successfully converted SAP Integrated Report 2023.pdf\n",
      "Converting the-economic-potential-of-generative-ai-the-next-productivity-frontier.pdf to markdown\n",
      "Started parsing the file under job_id 4b59acbb-a5d1-4f32-b40b-70ff8736ba60\n",
      "..Saving markdown to input_big_context/the-economic-potential-of-generative-ai-the-next-productivity-frontier.md\n",
      "Successfully converted the-economic-potential-of-generative-ai-the-next-productivity-frontier.pdf\n",
      "Converting the-state-of-ai-in-early-2024-final.pdf to markdown\n",
      "Started parsing the file under job_id 9f3595e5-da56-4786-83e4-201af4a0826d\n",
      ".Saving markdown to input_big_context/the-state-of-ai-in-early-2024-final.md\n",
      "Successfully converted the-state-of-ai-in-early-2024-final.pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        try:\n",
    "            print(f\"Converting {file} to markdown\")\n",
    "            md_text = LlamaParse(\n",
    "                result_type=\"markdown\", \n",
    "                verbose=True,\n",
    "                #use_vendor_multimodal_model=True,\n",
    "                #vendor_multimodal_model_name=\"openai-gpt-4o-mini\",\n",
    "                #vendor_multimodal_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                language=\"en\",\n",
    "                numWorkers=5).load_data(data_dir + file)\n",
    "            combined_md_text = \"\\n\\n\".join([doc.text for doc in md_text])\n",
    "            md_file_path = data_dir + file.replace(\".pdf\", \".md\")\n",
    "            print(f\"Saving markdown to {md_file_path}\")\n",
    "            with open(md_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(combined_md_text)\n",
    "            print(f\"Successfully converted {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted s10668-023-02933-7.pdf\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "tokens = encoding.encode(combined_md_text)\n",
    "print(len(tokens))\n",
    "\n",
    "with open(md_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(combined_md_text)\n",
    "    print(f\"Successfully converted {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186499\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "import tiktoken\n",
    "\n",
    "class Response(BaseModel):\n",
    "    question: str = Field(description=\"Question\")\n",
    "    ground_truth: str = Field(description=\"Ground Truth\")\n",
    "    references: List[str] = Field(description=\"List of document or reference names used\")\n",
    "\n",
    "class Responses(BaseModel):\n",
    "    responses: list[Response] = Field(description=\"List of responses\")\n",
    "\n",
    "documents = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".md\"):\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "            documents.append(Document(page_content=content, metadata={\"source\": file}))\n",
    "combined_documents_content = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Responses)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"documents\"],\n",
    "    partial_variables={\"format_output\": parser.get_format_instructions()},\n",
    "    template=\"\"\"\n",
    "You are tasked with generating 100 realistic and diverse business questions based on the documents provided below, which include SAP internal documents and other reports about varios business topics. \n",
    "Each question should be written from the perspective of SAP, focusing on what SAP can do to achieve specific business objectives (e.g., increase margins, improve sustainability, enhance product offerings), considering various factors.\n",
    "\n",
    "Integration of Diverse and Unlinked Knowledge Areas:\n",
    "- Each question must blend insights from multiple business domains (e.g., finance, sustainability, technology, operations)\n",
    "- Include concepts that are not necessarily semantically linked\n",
    "\n",
    "Multi-hop Information Synthesis Within and Across Documents:\n",
    "- Answers should require synthesizing multiple pieces of relevant information.\n",
    "- Draw information from multiple documents and multiple sections within a single document.\n",
    "- Ensure that multi-step reasoning is necessary to combine various information fragments into a comprehensive answer.\n",
    "\n",
    "Abstract Reasoning and Insight Generation:\n",
    "- Questions should push beyond simple fact retrieval and basic sensemaking.\n",
    "- Require abstract reasoning\n",
    "- Question should be global themed and require a understand of the whole documents to be answered\n",
    "\n",
    "For Each Question, Provide the Following:\n",
    "\n",
    "Question: \n",
    "- Formulate a complex business question that meets all the above constraints.\n",
    "\n",
    "Optimal Answer (Ground Truth):\n",
    "- Provide a comprehensive answer to the question.\n",
    "- The answer should synthesize all relevent information from the relevant documents and include abstract reasoning.\n",
    "\n",
    "Source Referenced:\n",
    "- Provide an array/list of the document names or identifiers that were used to form the answer.\n",
    "\n",
    "Question Examples:\n",
    "1. How can we capitalize on eco-friendly manufacturing practices to both improve our sustainability credentials and boost our financial performance?\n",
    "2. What innovative products should we consider integrating into our portfolio, and which current products have the highest potential for enhancement through machine learning technologies?\n",
    "\n",
    "The output MUST strictly adhere to the following JSON format, and NO other text MUST be included:    \n",
    "{format_output}\n",
    "\n",
    "Use only the following documents: \n",
    "<documents>\n",
    "{documents}\n",
    "</documents>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "tokens = encoding.encode(combined_documents_content)\n",
    "\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"documents\": combined_documents_content})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save LLM response to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open(\"./synthetic_data_big_context_test_citet2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(response.dict(), f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
