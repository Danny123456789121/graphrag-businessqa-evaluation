{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 199145, Requested 8112. Please try again in 2.177s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 199145, Requested 8112. Please try again in 2.177s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "main and sub-attributes essential for developing corporate sustainability business practices. Building on our objectives for this study, our primary research questions include, but are not limited, to what are the most influenceable metrics for corporate sustainability? And how can they be evaluated and ranked in a way that provide value to practitioners and scholars? After reviewing the literature, conceptual models, our research framework, and applying a Fuzzy Delphi method, we assess nine sustainability criteria and forty-five sub-criteria. We review our methods for employing the Fuzzy Analytical Hierarchical Process (FAHP) for calculations of weights for both the sub-criteria using a matrix of pairwise comparisons. Results are then discussed, and the last section provides main conclusions, contributions to the field, and avenues for aspects of corporate sustainability, social sustainability, and sustainable development for future researches.\n\n# 2. Literature Review\n\nThe definitions of sustainability have many interpretations, such as environmental protection, ecosystem resources, economic concerns, social acceptance, licensing and externalities, and many other perspectives. The recent literature shows that sustainable development is going beyond “green” to a more comprehensive, systematic, methodological, and integrated understanding of sustainability. Researchers and decision-makers are aware of the need for systematic sustainability assessments to evaluate complex systems to replace traditional and unsustainable business practices. Such assessments ultimately concentrate on historical strategies for sustainability, demonstrating the need to improve corporate sustainability programs over time, along with allocating resources that reduce sustainability risks. Further, organizations need to combine efficiency and market performance initiatives to develop strategic corporate sustainability opportunities [23].\n\nAsif et al. [24], conceptualized the integration of economic, social, and environmental bottom lines dimension by using a triple bottom line. This view of a corporation means that the efficiency and sustainability aspects of the integrated structure are matched together. Several models have been proposed to develop corporate sustainability in efforts to make it accessible, practical, and quantifiable. The wide range of sustainability frameworks is because of the variety of definitions of sustainable development, i.e. ecological sustainability, environmental efficiency, corporate citizenship, and TBL. In prior studies, one dimension of corporate sustainability is evaluated to define, measure, and sometimes test constructs and relationships. For instance, environmental sustainability frameworks concentrate on environmental issues by providing metrics for mitigating pollution, climate vulnerability, environmental degradation, land use, and loss of biodiversity [25].\n\nSocial sustainability models focus on societal and ethical facets of corporate sustainability, such as infrastructure, community welfare, human rights, health, equity, and education [26]. Further, economic sustainability involves the economic structure of organizations and concentrates on businesses seeking to optimize the company’s resources through social and environmental strategies [27]. Some studies proposed the two-dimensional sustainability frameworks in which two or more dimensions of corporate sustainability (such as environmental and social dimensions evaluated by providing sustainability indices and MCDA approaches). The fundamental model of corporate sustainability is shown in Figure 1.\n\n|CONTEXT|Economic|Environment|Social|\n|---|---|---|---|\n|CHANGE|Systematic|Organizational|Individual|\n\nFigure 1. Conventional Corporate Sustainability Model.\n\n# Sustainability 2020, 12, 8747\n\nConcerns regarding the social and environmental effects of sustainability must be weighted, but economic viability should not be threatened. The company’s financial performance can be affected and impacts its risk of survival if it fails to give due attention to its economic performance [28]. Longoni and Cagliano [29] argued that managing and balancing TBL performance is paramount. The authors acknowledge the difficulties of doing this while also trying to understand any negative tradeoffs between the three sustainability dimensions.\n\nThe International Organization of Standardization (ISO) and the Global Reporting Initiative (GRI) systems assist companies in integrating sustainable development and TBL performance. GRI measures and reports the “material” performance of companies and its business activities and its effectiveness in multiple dimensions, i.e., three folds result to the public, most of the time through sustainability reports [30]. Several sustainability indices have been developed to highlight sustainability activities so that investors can consider the sustainable performance of enterprises. By analyzing the sustainability practices by each corporation, the sustainability indices act as a knowledge intermediary of companies with their different players (including business specialists, shareholders, and financial intermediaries). Specialized data accessed by neutral parties are seen by these intermediaries as objective. Conventional definitions of sustainability suggest that the businesses are supposed to be listed only if they are more socially and environmentally responsible than their competitors within these stock indexes. Sustainability stock indexes can, therefore, be treated as suitable sustainability performance indicators. Weber [31] suggests sustainability guidance that describes the most relevant performance metrics and issues in six banking industries. They showed specific important issues are shared by many industries, particularly social sustainability aspects, whereas others are unique in a sector.\n\nSeveral researchers have used MCDA methods to measure the company’s sustainability performance. A list of different MCDA approaches used to develop a sustainability framework is shown in Table 1.\n\n**Multi-Criteria Decision Analysis (MCDA) Methods in Corporate Sustainability**\n|N.|Sustainability Research Conducted|MCDA Method|Year|Reference|\n|---|---|---|---|---|\n|01|The assessment and weigh of the CSR program criteria in industry; and supplier assessment|AHP|2018|[32,33]|\n|02|A geographic information system sustainability model based on GeoUmbriaSUIT|TOPSIS|2018|[34]|\n|03|Identifying the CSR criteria as well as propose and priorities the alternatives to improve the supply chain performance.|AHP-TOPSIS|2018|[35]|\n|04|Selection of sustainable green Supplier under Uncertain Environment: Evidence from Thailand Palm oil products Industry|Fuzzy DEMATEL|2019|[36]|\n|05|Prioritizing and selection of a socially sustainable supplier for social sustainability|TODIM|2019|[37]|\n|06|Framework of sustainability balanced score"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 198498, Requested 7446. Please try again in 1.783s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 198498, Requested 7446. Please try again in 1.783s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": ", 86–94. [CrossRef]\n19. Worldometers. Worldometerse. 2020. Available online: https://www.worldometers.info/coronavirus (accessed on 23 June 2020).\n20. Hakovirta, M.; Denuwara, N. How COVID-19 Redefines the Concept of Sustainability. Sustainability 2020, 12, 3727. [CrossRef]\n21. Maletic, M.; Maletic, D.; Dahlgaard, J.; Dahlgaard-Park, S.M.; Gomišcek, B. Do corporate sustainability practices enhance organizational economic performance? Int. J. Qual. Serv. Sci. 2015, 7, 184–200. [CrossRef]\n22. Asif, M.; Searcy, C.; Zutshi, A.; Fisscher, O.A. An integrated management systems approach to corporate social responsibility. J. Clean. Prod. 2013, 56, 7–17. [CrossRef]\n23. Ikram, M.; Zhang, Q.; Sroufe, R.; Shah, P.S.Z.A. Towards a sustainable environment: The nexus between ISO 14001, renewable energy consumption, access to electricity, agriculture and CO2 emissions in SAARC countries. Sustain. Prod. Consum. 2020, 22, 218–230. [CrossRef]\n24. Amrutha, V.; Geetha, S. A systematic review on green human resource management: Implications for social sustainability. J. Clean. Prod. 2020, 247, 119131. [CrossRef]\n25. Landrum, N.E.; Ohsowski, B. Identifying Worldviews on Corporate Sustainability: A Content Analysis of Corporate Sustainability Reports. Bus. Strateg. Environ. 2017, 27, 128–151. [CrossRef]\n\n# Sustainability 2020, 12, 8747\n\n# References\n\n1. Landrum, N.E. Stages of Corporate Sustainability: Integrating the Strong Sustainability Worldview. Organ. Environ. 2018, 31, 287–313. [CrossRef]\n2. Longoni, A.; Cagliano, R. Sustainable Innovativeness and the Triple Bottom Line: The Role of Organizational Time Perspective. J. Bus. Ethics 2018, 151, 1097–1120. [CrossRef]\n3. Stacchezzini, R.; Melloni, G.; Lai, A. Sustainability management and reporting: The role of integrated reporting for communicating corporate sustainability management. J. Clean. Prod. 2016, 136, 102–110. [CrossRef]\n4. Weber, O. Corporate sustainability and financial performance of Chinese banks. Sustain. Accounting Manag. Policy J. 2017, 8, 358–385. [CrossRef]\n5. Karaman, A.S.; Akman, E. Taking-off corporate social responsibility programs: An AHP application in airline industry. J. Air Transp. Manag. 2018, 68, 187–197. [CrossRef]\n6. Handfield, R.; Walton, S.V.; Sroufe, R.; Melnyk, S.A. Applying environmental criteria to supplier assessment: A study in the application of the Analytical Hierarchy Process. Eur. J. Oper. Res. 2002, 141, 70–87. [CrossRef]\n7. Boggia, A.; Massei, G.; Pace, E.; Rocchi, L.; Paolotti, L.; Attard, M. Spatial multicriteria analysis for sustainability assessment: A new model for decision making. Land Use Policy 2018, 71, 281–292. [CrossRef]\n8. Tyagi, M.; Kumar, P.; Kumar, D. Assessment of CSR based supply chain performance system using an integrated fuzzy AHP-TOPSIS approach. Int. J. Logist. Res. Appl. 2018, 21, 378–406. [CrossRef]\n9. Phochanikorn, P.; Tan, C. An Integrated Multi-Criteria Decision-Making Model Based on Prospect Theory for Green Supplier Selection under Uncertain Environment: A Case Study of the Thailand Palm Oil Products Industry. Sustainability 2019, 11, 1872. [CrossRef]\n10. Bai, C.; Kusi-Sarpong, S.; Ahmadi, H.B.; Sarkis, J. Social sustainable supplier evaluation and selection: A group decision-support approach. Int. J. Prod. Res. 2019, 57, 7046–7067. [CrossRef]\n11. Tsai, W.-H.; Chou, W.-C.; Hsu, W. The sustainability balanced scorecard as a framework for selecting socially responsible investment: An effective MCDM model. J. Oper. Res. Soc. 2009, 60, 1396–1410. [CrossRef]\n12. Kusi-Sarpong, S.; Gupta, H.; Sarkis, J. A supply chain sustainability innovation framework and evaluation methodology. Int. J. Prod. Res. 2019, 57, 1990–2008. [CrossRef]\n13. Liao, P.-C.; Xue, J.; Liu, B.; Fang, D. Selection of the approach for producing a weighting scheme for the CSR evaluation framework. KSCE J. Civ. Eng. 2015, 19, 1549–1559. [CrossRef]\n14. Esteves, A. Evaluating community investments in the mining sector using multi-criteria decision analysis to integrate SIA with"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 199366, Requested 8172. Please try again in 2.261s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 199366, Requested 8172. Please try again in 2.261s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "have in the past been looked at individually and as environmental impacts of firms. Due to the COVID-19 pandemic, new insights include the Pandemic, along with Economic and Corporate Governance are top-ranked criteria to focus on improving corporate sustainability practices. Whereas, emergency response plan, social distance and modification in the number of working hours, commitment to climate changes, and JIT and lean delivery emerged in the top-ranked sub-criteria.\n\nThe outcomes of our work lead us to call for more action from decision-makers and policymakers as sustainability provides an integration opportunity with dynamic social benefits. Moreover, scholars also can consider relevant criteria from literature, and building on this research when combining insights from experts and develop a new, more integrated, corporate sustainability model. The research in this study also contributes to developing theory with contemporary approaches for decision-making analysis to show corporate sustainability theory can and should include more social sustainability practices. When doing so, we hope the efforts of both researchers and practitioners will be able to find more dynamic relationships between practices, firm performance, and resiliency to overcome future pandemics. Our results also provide insights to scholars wanting to further develop theories considering Multiple Management Standards (MMSs), the Stakeholder Theory [108], Integrated Management [109], Integrated Management Systems (IMS), and possibilities for a new theory such as a social sustainability-based view (SBV) of the firm.\n\nThe methods used in this study support decision-making in a powerful and relatively simple way. This useful perspective addresses decision-makers and researchers dealing with resource allocation or project prioritization. These methods may be applied toward further replications by future studies. The methods described in this study help in measuring strategic goals as a set of scored criteria for determining project selection. Multi-criterion decision-making methodologies have proven to be useful in the application for manufacturing sectors. We can foresee the need for more work with these types of firms using the application of MCDA in complex interdisciplinary and social sustainability problems. We recommend future studies include developing FAHP techniques in combination with other analysis opportunities in an integrated system, supply chains, cities, and even entire countries aiming to tackle grand challenges, for example, the United Nations’ Sustainable Development Goals (SDGs).\n\n# Sustainability 2020, 12, 8747\n\nFinally, this research is the first of its kind considering the development of an integrated social sustainability model with social sustainability criteria that include the pandemic and COVID-19. Outcomes of this study can help organizations to consider the most suitable programs and systems for advancing corporate sustainability while also considering stakeholders and social sustainability. As managerial implications, we see sustainable development enabling companies to integrate audits, engage personnel, and optimizing companies’ processes and resource allocation. Social sustainability is dynamic, not easily understood, and can be disruptive if not taken into account as part of corporate social sustainability at every level of the firm.\n\nThis study presents some limitations. We address the limitation related to the developed models based on experts’ assessments. By choosing this approach, it is assumed that bias will always occur in the process. Future applications of this approach may include a diversified set of experts and managers from companies that may be more impacted by systems implementations. Another limitation is concerning data availability. Managers involved in an MCDA process may have limited access to data concerning all criteria or even the entire multinational company as a consequence of a lack of integrated information. Moreover, these issues can be solved by careful consideration of practitioners involved in the decision-making process when realizing that inputs are qualitative, in nature, and the time needed for options assessments. Then, the criteria and outcomes should be revisited when assessing corporate sustainability performance over time.\n\n# Author Contributions\n\nconceptualization, M.I.; methodology, M.I.; software, M.I.; validation, M.I., Q.Z., R.S and M.F.; formal analysis, M.I.; investigation, M.I, Q.Z., R.S. and M.F; resources, M.I. and Q.Z.; data curation, M.I.; writing—original draft preparation, M.I.; writing—review and editing, M.I.,Q.Z.,R.S. and M.F; visualization, M.I.; supervision, Q.Z. and R.S.; project administration, Q.Z. and R.S; funding acquisition, Q.Z. All authors have read and agreed to the published version of the manuscript.\n\n# Funding\n\nThis research was funded by, National Natural Science Foundation of China, Grant/Award Number: 71572115; Major Program of Social Science Foundation of Guangdong, Grant/Award Number: 2016WZDXM005; 2020 Guangdong 13th-Five-Year-Plan Philosophical and Social Science Fund (#GD20CGL28); and Natural Science Foundation of SZU, Grant/Award Number: 836.\n\n# Acknowledgments\n\nThe authors thank the anonymous reviewers and Editor for their valuable contributions that improved this manuscript.\n\n# Conflicts of Interest\n\nThe authors declare no conflict of interest.\n\n# Appendix A\n\n# Table A1. List of experts.\n\n|No.|Designation|Qualification|Age|Organization|\n|---|---|---|---|---|\n|1|Director|PhD|43|Ministry of climate change|\n|2|Professor|PhD|50|Nanjing University|\n|3|Deputy Director|PhD|56|SGS Group, Shenzhen|\n|4|Manager Quality control|Graduation|37|Walmart, Beijing|\n|5|Health & Safety Manager|Graduation|38|Honda, Guangzhou|\n|6|Director Shipping|Graduation|47|YTS auto spare parts Guangzhou|\n|7|Associate Professor|PhD|42|Zhejiang University|\n|8|Executive director|Graduation|53|Ministry of Energy & Power|\n\n# References\n\n1. Brundtland World Commission on Environment and Development. Report of the World Commission on Environment and Development: Our Common Future; United"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 198131, Requested 7729. Please try again in 1.758s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 198131, Requested 7729. Please try again in 1.758s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "the ranking of each criterion, and the criteria acquires higher ranking are those that have higher overall performance score RC .i\n\n# L. Xia, et al.\n\n# Environmental Impact Assessment Review 85 (2020) 106459\n\n# Table 2\n\n# Proposed measures.\n\n|Clustered aspect| |SRM criteria| |Reference|\n|---|---|---|---|---|\n|A1 Economics| |C1|extending product's life span|Bocken et al., 2016|\n| | |C2|utilizing optimal capability|Lin and Tseng, 2016|\n| | |C3|applying quality management mechanism|Lim et al., 2017|\n| | |C4|optimizing horizontal logistics|Defryn et al., 2019; Tseng et al., 2019b|\n|A2 Environment| |C5|adopting eco-design approach|Eksi and Karaosmanoglu, 2018|\n| | |C6|developing cleaner technology|Büyüközkan and Çifçi, 2013|\n| | |C7|improving the transparency of sustainability reports|Roca and Searcy, 2012|\n| | |C8|enhancing decision making resilience|Galpin et al., 2015; Islam et al., 2019|\n|A3 Society| |C9|organizing synergetic involvement|Tseng et al., 2018; Wu et al., 2019b|\n| | |C10|increasing employee and customer awareness|Shi et al., 2017|\n| | |C11|raising institution's support and policy measures|Singh et al., 2019|\n| | |C12|advocating corporate culture|Bonn and Fisher, 2011; Tseng et al., 2019a|\n|A4 Socio-economics| |C13|improving stakeholder interactions|Frooman, 1999; Lin et al., 2019|\n| | |C14|building value proposition|Kristensen and Renmmen, 2019|\n| | |C15|building eco-friendly rewarding systems for employees|Lozano, 2015|\n|A5 Eco-efficiency| |C16|encouraging environmental innovation|Liao et al., 2018|\n| | |C17|pushing the sustainability agenda into government policy|Dauvergne and Lister, 2012; Heikkurinen et al., 2019|\n| | |C18|redesigning the consumer's offer|Baines et al., 2007; Heikkurinen et al., 2019|\n|A6 Socio-environment| |C19|pursuing eco-resource efficiency orientation|Von Geibler et al., 2016; Horton et al., 2016|\n| | |C20|selecting and collaborating with green supplier|Sarkis and Talluri, 2002|\n| | |C21|enhancing environmental awareness|Matos and Hall, 2007; Eltayeb et al., 2011; Wu et al., 2019a|\n\n# 4. Results\n\nIn this section, the computational results of FCM, Entropy weight and VS-TOPSIS is present as below, respectively.\n\n1. The cluster matrix in FCM was built on the survey data from experts. Then Eq. (1)-Eq. (4) can be used to compute the transitive closure matrix. In this study, the frequency of self-composition square was eight, and λ = 0.858 was adopted in this study for acquiring a proper clustering result. Accordingly, Table 2 reveals that these 21 SRM criteria was clustered into six categories, thereinto, C1-C4 was clustered into the aspect of economic, C5-C8 fall into the aspect of environment, C9-C12 belongs to the aspect of society, C13-C15 was included in the aspect of socio-economic, C16-C18 was considered in the aspect of eco-efficiency, C19-C21 was covered in the aspect of socio-environment.\n2. After scraping the social media data based on Python software, these accumulated frequencies must be transferred into the corresponding entropy weight by means of Eq. (5)–(8). Specifically, Appendix A shows the calculated entropy weight of 21 criteria and 6 aspects.\n3. The expert group was consisted of 5 professors, 10 senior managers and 10 senior engineers who had more than 5 years of work or research experience in Chinese automobile industry. Each expert was required to fill out two questionnaires so as to generate the qualitative assessment matrix and the hesitant matrix, respectively. Additionally, all the linguistic preference must be integrated with the corresponding hesitancy index in order to convert them into unified vague value in contrast with Table 1 in using Eq. (9). Table 3 presents the transferred vague set assessment matrix, taking the interrelationship from C3 to C1 as an example, the detailed transformation process is [0.7 − 0.7 ∗ 0.3, 0.7 + 0.7 ∗ 0.5] = [0.550, 0.850].\n4. Utilizing Eqs. (10)–(17) to compute the profit ratio matrix. Then, the aggregated matrix S can be obtained through aggregating all the individual proration matrix in using Eq. (18), as shown in Table 4.\n5. Once the aggregated profit ratio matrix is obtained, the decision matrix can be derived and normalized by adopting Eq. (19) and Eq. (20), respectively. The entropy weight is integrated to weight the normalized"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194831, Requested 8034. Please try again in 859ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194831, Requested 8034. Please try again in 859ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "situation.\n\nRaising institution's support and policy measures (11) played a significant role in improving CS performance for Chinese automobile industry. In prior literature, the importance of institutional support and government-support measures in stimulating technological innovation was researched extensively (Veblen, 1915; Nelson, 2008). Lundvall (1992) also emphasized the embedding organizations and institutions can actively advance the role of research and development in each industry. This study has found the similar conclusion in the Chinese automobile industry. For example, in response to the policy of energy-saving and emission-reduction, Chery has undertaken many national key researches and development tasks of new energy technology, and consequently achieved a profit increase of 35.7% in 2017. This evidence proves that the institution's support and policy can push firms towards CS goal.\n\nMoreover, one of the goals of SRM is to promote resource and energy optimization, better infrastructure, and access to basic amenities, green environment through organizing synergetic involvement (C9). Organizing synergetic involvement implies firms should align stakeholders' engagement with a firm's CS target. In the real situation, firms always seek more involvement or alliances among stakeholders' in supply chain networks, for instance, China First Automobile Group (FAW) always aims at protecting and aligning its stakeholders, which has re-established it as the distributor support department to support distributors. Furthermore, existed literature has clearly suggested that synergetic involvement among stakeholders' is essential to improve CS performance (Bocken et al., 2014; Schoenherr and Speier-Pero, 2015). Thus, firms should carefully maintain long term relationships between firms and key stakeholders, and align them with the CS target.\n\n# 6. Conclusions\n\nThe findings reveal that with the integration of eco-efficiency, socio-environmental and socio-economic aspects into the TBL hierarchy, the new framework provides a more comprehensive consideration of CS than previous discussions. Chinese automobile firms that want to acquire the long-term benefit and attain the competitive advantage need to launch the SRM practice of encouraging environmental innovation, which can effectively and efficiently help firms develop a more environment-friendly technology and methods. In addition, the SRM practice of redesigning the consumers' offer can enable firms to meet the dynamic consumers' demand in time. The result also indicates that raising institutions' support and policy measures plays a crucial role in stimulating R&D activities, which can obtain positive performance internally and externally. Finally, firms adopt SRM practice of organizing synergetic involvement with the purpose of aligning stakeholders' engagement with CS goal, and synergetic involvement can function on CS and decision-making process significantly.\n\nThis study presents three main contributions as follows: (1) it provides a theoretical contribution through collecting SRM measures/practices from previous literature and establish a comprehensive framework between SRM and CS. Thereinto, eco-efficiency, socio-environmental and socio-economic aspects were proposed to supplement TBL. (2) it provides a methodological contribution by integrating VS theory and TOPSIS method to study the interrelationship between SRM and CS, as well as gathering social media information and transfers them into corresponding entropy weight and make an improvement to efficiently reduce time consumption of decision making. Additionally, the result of sensitivity analysis shows that the integration with social media data can help effectively eliminate the subjective judgement, as well as identify practical gaps in real situation. (3) the obtained analytical results in this study can help decision-makers to select the decisive SRM practice which can be used to provide precise guidelines for Chinese automobile industry towards CS goal.\n\nThis study has several limitations that need future studies to overcome. First, the selected 21 SRM practices may not enough to reveal the real situation, thus future study may require taking more proper SRM practices into account. Moreover, this study proposed VS-TOPSIS to measure the geometric interrelationship among alternatives, while the causal relationship cannot be reflected. Hence, future study may need to consider further modifying this method.\n\n7\n\n# L. Xia, et al.\n\n# Environmental Impact Assessment Review 85 (2020) 106459\n\n# Declaration of Competing Interest\n\nThe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# Acknowledgments\n\nThis research was funded by the National Natural Science Foundation of China (71828102, 71921001 and 72042008), and the Foundation of President of China National Institute of Standardization (282019Y-6772).\n\n# Appendix A. The entropy weight of focal firms based on 21 criteria and 6 aspects\n\n| |Geely Automobile Group|Great Wall Motor Company Limited|Chery Automobile Co., Ltd.|China First Automobile Group Co., Ltd|Total|\n|---|---|---|---|---|---|\n|A1|0.1646|0.1597|0.1729|0.1724|0.1683|\n|A2|0.1768|0.1623|0.1618|0.1652|0.1670|\n|A3|0.1638|0.1629|0.1747|0.1651|0.1643|\n|A4|0.1639|0.1737|0.1628|0.1657|0.1654|\n|A5|0.1668|0.1783|0.1615|0.1649|0.1702|\n|A6|0.1641|0.1631|0.1664|0.1668|0.1648|\n|C1|0.0502|0.0470|0.0473|0.0473|0.0478|\n|C2|0.0467|0.0474|0."
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 193060, Requested 7344. Please try again in 121ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 193060, Requested 7344. Please try again in 121ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "|0.1668|0.1783|0.1615|0.1649|0.1702|\n|A6|0.1641|0.1631|0.1664|0.1668|0.1648|\n|C1|0.0502|0.0470|0.0473|0.0473|0.0478|\n|C2|0.0467|0.0474|0.0467|0.0466|0.0475|\n|C3|0.0460|0.0465|0.0469|0.0516|0.0476|\n|C4|0.0464|0.0469|0.0480|0.0488|0.0458|\n|C5|0.0507|0.0463|0.0471|0.0466|0.0480|\n|C6|0.0509|0.0469|0.0520|0.0465|0.0477|\n|C7|0.0458|0.0520|0.0468|0.0466|0.0490|\n|C8|0.0475|0.0463|0.0470|0.0525|0.0476|\n|C9|0.0485|0.0463|0.0488|0.0465|0.0473|\n|C10|0.0455|0.0512|0.0471|0.0465|0.0472|\n|C11|0.0457|0.0477|0.0467|0.0471|0.0477|\n|C12|0.0463|0.0463|0.0491|0.0465|0.0473|\n|C13|0.0457|0.0490|0.0470|0.0480|0.0477|\n|C14|0.0459|0.0463|0.0472|0.0474|0.0469|\n|C15|0.0497|0.0463|0.0479|0.0466|0.0480|\n|C16|0.0468|0.0506|0.0467|0.0465|0.0487|\n|C17|0.0457|0.0507|0.0473|0.0467|0.0477|\n|C18|0.0483|0.0464|0.0468|0.0514|0.0475|\n|C19|0.0473|0.0464|0.0471|0.0465|0.0477|\n|C20|0.0486|0.0476|0.0490|0.0473|0.0480|\n|C21|0.0516|0.0463|0.0474|0.0465|0.0474|\n\n# Appendix B. The overall performance score of 21 criteria and 6 aspects\n\n| |E+|E|RCi|Ranking|\n|---|---|---|---|---|\n|A1|0.389|0.493|0.559|5|\n|A2|0.414|0.528|0.560|3|\n|A3|0.408|0.522|0.561|2|\n|A4|0.411|0.520|0.559|6|\n|A5|0.473|0.606|0.561|1|\n|A6|0.380|0.484|0.560|4|\n|C1|0.220|0.256|0.538|9|\n|C2|0.220|0.240|0.522|15|\n|C3|0.206|0.222|0.518|16|\n|C4|0.188|0.259|0.579|3|\n|C5|0.223|0.256|0.535|10|\n|C6|0.222|0.245|0.525|13|\n|C7|0.209|0.230|0.523|14|\n|C8|0.197|0.244|0.553|7|\n|C9|0.208|0.281|0.575|4|\n|C10|0.245|0.240|0.495|19|\n|C11|0.205|0.293|0.588|2|\n|C12|0.256|0.287|0.528|12|\n|C13|0.250|0.263|0.514|17|\n|C14|0.227|0.258|0.532|11|\n|C15|0.223|0.204|0.478|21|\n|C16|0.173|0.279|0.618|1|\n|C17|0.243|0.227|0.483|20|\n|C18|0.193|0.253|0.567|5|\n|C19|0.217|0.223|0.507|18|\n|C20|0.189|0.220|0.538|8|\n|C21|0.188|0.233|0.554|6|\n\n# L. Xia, et al.\n\n#"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 193034, Requested 8172. Please try again in 361ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 193034, Requested 8172. Please try again in 361ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "9. Extended theory of planned behaviour for promoting construction waste recycling in Hong Kong. Waste Manag. 83, 161–170.\n\nMatos, S., Hall, J., 2007. Integrating sustainable development in the supply chain: the case of life cycle assessment in oil and gas and agricultural biotechnology. J. Oper. Manag. 25 (6), 1083–1102.\n\nMeng, X., Han, J., 2018. Roads, economy, population density, and co2: a city-scaled causality analysis. Resour. Conserv. Recycl. 128, 508–515.\n\nNelson, R.R., 2008. Economic development from the perspective of evolutionary economic theory. Oxf. Dev. Stud. 36 (1), 9–21.\n\nNg, K.S., Yang, A., Yakovleva, N., 2019. Sustainable waste management through synergistic utilisation of commercial and domestic organic waste for efficient resource recovery and valorisation in the Uk. J. Clean. Prod. 227, 248–262.\n\nQiao, Y.-K., Peng, F.-L., Sabri, S., et al., 2019. Socio-environmental costs of underground space use for urban sustainability. Sustain. Cities Soc. 51, 101757.\n\nRoca, L.C., Searcy, C., 2012. An analysis of indicators disclosed in corporate sustainability reports. J. Clean. Prod. 20, 103–118.\n\nSanginga, N., Dashiell, K.E., Diels, J., et al., 2003. Sustainable resource management coupled to resilient germplasm to provide new intensive cereal–grain–legume–livestock systems in the dry savanna. Agric. Ecosyst. Environ. 100 (2–3), 305–314.\n\nSarkis, J., Talluri, S., 2002. A model for strategic supplier selection. J. Supply Chain Manag. 38 (1), 18–28.\n\nSchoenherr, T., Speier-Pero, C., 2015. Data science, predictive analytics, and big data in supply chain management: current state and future potential. J. Bus. Logist. 36 (1), 120–132.\n\nShi, L., Wu, K.J., Tseng, M.L., 2017. Improving corporate sustainable development by using an interdependent closed-loop hierarchical structure. Resour. Conserv. Recycl. 119, 24–35.\n\nSingh, J., Cooper, T., Cole, C., et al., 2019. Evaluating approaches to resource management in consumer product sectors - an overview of global practices. J. Clean. Prod. 224, 218–237.\n\nSong, M., Fisher, R., Kwoh, Y., 2019. Technological challenges of green innovation and sustainable resource management with large scale data. Technol. Forecast. Soc. Chang. 144, 361–368.\n\nSpiller, R., 2000. Ethical business and investment: a model for business and society. J. Bus. Ethics 27, 149–160.\n\nTseng, M.L., 2017. Using social media and qualitative and quantitative information scales to benchmark corporate sustainability. J. Clean. Prod. 142, 727–738.\n\nTseng, M.L., Bui, T.D., 2017. Identifying eco-innovation in industrial symbiosis under linguistic preferences: a novel hierarchical approach. J. Clean. Prod. 140, 1376–1389.\n\nTseng, M.L., Wu, K.J., Li, M., et al., 2019a. A hierarchical framework for assessing corporate sustainability performance using a hybrid fuzzy synthetic method-DEMATEL. Technol. Forecast. Soc. Chang. 144, 524–533.\n\nTseng, M.L., Wu, K.J., Lim, M.K., et al., 2019b. Data-driven sustainable supply chain management performance: a hierarchical structure assessment under uncertainties. J. Clean. Prod. 227, 760–771.\n\nVeblen, T., 1915. Imperial Germany and the Industrial Revolution. Macmillan, London.\n\nVon Geibler, J., Cordaro, F., Kennedy, K., et al., 2016. Integrating resource efficiency in business strategies: a mixed-method approach for environmental life cycle assessment in the single-serve coffee value chain. J. Clean. Prod. 115, 62–74.\n\nWu, K.J., Liao, C.J., Tseng, M.L., et al., 2016. Multi-attribute approach to sustainable supply chain management under uncertainty. Ind. Manag. Data Syst. 116 (4), 777–800.\n\nWu, K.J., Zhu, Y., Tseng, M.L., et al., 2018. Developing a hierarchical structure of the co-benefits of the triple bottom line under uncertainty. J. Clean. Prod. 195, 908–918.\n\nWu, K.J., Zhu, Y., Chen, Q., Tseng, M.L., 2019a. Building sustainable tourism hierarchical framework: coordinated triple bottom line approach in linguistic preferences. J.\n\nL. Xia, et al. Environmental Impact Assessment Review 85 (2020) 106459\n\nWu, K.J., Tseng, M.L., Lim, M.K., et al., 2019b. Causal sustainable resource management model using a hierarchical structure and linguistic preferences. J. Clean. Prod. 229, 157–168.\n\nWu, K.J., G"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 153, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 195897, Requested 6884. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 195897, Requested 6884. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "2020, 12, 10584\n\n# 5.3. Future Research Directions\n\nAlthough we believe that our study can provide a new framework and a decision-making tool for selecting and evaluating suppliers in the sustainable supply chain, our research work could be expanded and improved in future research. Some future directions are identified as follows:\n\n- This study was more methodologically oriented as the research showed how the methodology can integrate various complex issues in managerial decision-making. As the problem size increases, the applicability and accuracy of the model will require further investigation. For example, what if the number of factors increases regarding the number of alternatives or criteria?\n- A complete validation of the study will be undertaken by considering more scenarios. Experimenting with the methodology would be worthwhile to determine if all scenarios are supportive. For example, what if all the data were known, or only known data were utilized? What if none of the data were known and it was a completely new product with new suppliers? How well can the model learn? These are all questions that may be asked in various experimental scenarios or in long-term longitudinal studies.\n- It will be also useful to expand the BN model with indicators for some criteria and to consider the decision-maker characteristics; for example, would supply chain managers differ from engineering or marketing managers?\n- Furthermore, the proposed model can be solved by using other approaches and the obtained results can be compared with each other using the Spearman rank correlation method, such as multiple criteria tools including ANP, TOPSIS and PROMETHEE, to name a few. Otherwise, different methods can be compared regarding the time, the complexity and the restriction on the number of alternatives or criteria used in the selection process in order to identify which method is more robust.\n- Additionally, this study can be extended to other domains for evaluation and selection decision-making problems. The update of the evaluation criteria according to each specific case will be necessary.\n\nFinally, we sought to integrate a series of tools and found the technique useful and feasible. Thus, we continue to build on the important supplier selection field and knowledge.\n\n# Author Contributions\n\nConceptualization, N.K., A.J. and J.S.; Methodology, N.K., A.J. and J.S.; Visualization N.K. and A.J.; Formal Analysis & investigation, N.K. and A.J.; Validation, A.J. and J.S.; Resources and Data curation N.K. and A.J.; Supervision, J.S.; Writing—Original draft, N.K. and A.J.; Writing—Review & editing, N.K., A.J. and J.S. All authors have read and agreed to the published version of the manuscript.\n\n# Funding\n\nThis research received no external funding.\n\n# Conflicts of Interest\n\nThe authors declare no conflict of interest.\n\n# References\n\n1. Rostamzadeh, R.; Ghorabaee, M.K.; Govindan, K.; Esmaeili, A.; Nobar, H.B.K. Evaluation of sustainable supply chain risk management using an integrated fuzzy TOPSIS- CRITIC approach. J. Clean. Prod. 2018, 175, 651–669. [CrossRef]\n2. Bai, C.; Kusi-Sarpong, S.; Ahmadi, H.B.; Sarkis, J. Social sustainable supplier evaluation and selection: A group decision-support approach. Int. J. Prod. Res. 2019, 57, 7046–7067. [CrossRef]\n3. Chai, J.; Liu, J.N.K.; Ngai, E.W.T. Application of decision-making techniques in supplier selection: A systematic review of literature. Expert Syst. Appl. 2013, 40, 3872–3885. [CrossRef]\n4. Jain, V.; Kumar, S.; Kumar, A.; Chandra, C. An integrated buyer initiated decision-making process for green supplier selection. J. Manuf. Syst. 2016, 41, 256–265. [CrossRef]\n5. Zimmer, K.; Fröhling, M.; Schultmann, F. Sustainable supplier management—A review of models supporting sustainable supplier selection, monitoring and development. Int. J. Prod. Res. 2016, 54, 1412–1442. [CrossRef]\n6. Konys, A. Green Supplier Selection Criteria: From a Literature Review to a Comprehensive Knowledge Base. Sustainability 2019, 11, 4208. [CrossRef]\n7. Chowdhury, P.; Paul, S.K. Applications of MCDM methods in research on corporate sustainability: A systematic literature review. Manag. Environ. Qual. Int. J. 2020, 31, 385–405. [CrossRef]\n8. Wang, X.; Cai, J.; Xiao, J. A Novel Decision-Making Framework for Sustainable Supplier Selection Considering Interaction among Criteria with Heterogeneous Information. Sustainability 2019, 11, 2820. [CrossRef]\n9. Sarkis, J.; Dhavale, D.G. Supplier selection for sustainable operations: A triple-bottom-line approach using a Bayesian framework. Int. J. Prod. Econ. 2015, 166, 177–191. [CrossRef]\n10. Govindan, K.; Rajendran, S.; Sarkis, J.; Murugesan, P. Multi criteria decision making approaches for green supplier evaluation and selection: A literature review. J. Clean. Prod. 2015, 98, 66–83. [CrossRef]\n11. Dweiri, F.; Kumar, S.; Khan, S.A.; Jain, V. Designing an integrated AHP based decision support system for supplier selection in automotive industry. Expert Syst. Appl. 2016,"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 193533, Requested 8172. Please try again in 511ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 193533, Requested 8172. Please try again in 511ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "hierarchy process and analytic network process: An overview of applications. Manag. Decis. 2010, 48, 775–808. [CrossRef]\n21. Forman, E.H.; Gass, S.I. The Analytic Hierarchy Process—An Exposition. Oper. Res. 2001, 49, 469–486. [CrossRef]\n22. Shah, S.A.A.; Solangi, Y.; Ikram, M. Analysis of barriers to the adoption of cleaner energy technologies in Pakistan using Modified Delphi and Fuzzy Analytical Hierarchy Process. J. Clean. Prod. 2019, 235, 1037–1050. [CrossRef]\n23. Lee, M.; Pham, H.; Zhang, X. A methodology for priority setting with application to software development process. Eur. J. Oper. Res. 1999, 118, 375–389. [CrossRef]\n\n# Sustainability 2020, 12, 8747\n\n# References\n\n1. Amran, A.; Lee, S.P.; Devi, S.S. The Influence of Governance Structure and Strategic Corporate Social Responsibility Toward Sustainability Reporting Quality. Bus. Strateg. Environ. 2014, 23, 217–235. [CrossRef]\n2. Adams, R.J.; Jeanrenaud, S.; Bessant, J.; Denyer, D.; Overy, P. Sustainability-oriented Innovation: A Systematic Review. Int. J. Manag. Rev. 2016, 18, 180–205. [CrossRef]\n3. Kim, S.; Ji, Y. Chinese Consumers’ Expectations of Corporate Communication on CSR and Sustainability. Corp. Soc. Responsib. Environ. Manag. 2017, 24, 570–588. [CrossRef]\n4. Dyllick, T.; Muff, K. Clarifying the Meaning of Sustainable Business. Organ. Environ. 2016, 29, 156–174. [CrossRef]\n5. Labuschagne, C.; Brent, A.C.; Van Erck, R.P. Assessing the sustainability performances of industries. J. Clean. Prod. 2005, 13, 373–385. [CrossRef]\n6. Ordonez-Ponce, E.; Clarke, A. Sustainability cross-sector partnerships: The strategic role of organizational structures. Corp. Soc. Responsib. Environ. Manag. 2020, 27, 2122–2134. [CrossRef]\n7. Sroufe, R. Effects of environmental management systems on environmental management practices and operations. Prod. Oper. Manag. 2009, 12, 416–431. [CrossRef]\n8. Ikram, M.; Mahmoudi, A.; Shah, S.Z.A.; Mohsin, M. Forecasting number of ISO 14001 certifications of selected countries: Application of even GM (1,1), DGM, and NDGM models. Environ. Sci. Pollut. Res. 2019, 26, 12505–12521. [CrossRef]\n9. Yong, J.Y.; Yusliza, M.Y.; Ramayah, T.; Jabbour, C.J.C.; Sehnem, S.; Mani, V. Pathways towards sustainability in manufacturing organizations: Empirical evidence on the role of green human resource management. Bus. Strat. Environ. 2020, 29, 212–228. [CrossRef]\n10. Toft, K.H.; Rüdiger, M. Mapping corporate climate change ethics: Responses among three Danish energy firms. Energy Res. Soc. Sci. 2020, 59, 101286. [CrossRef]\n11. Souza, J.P.E.; Alves, J.M. Lean-integrated management system: A model for sustainability improvement. J. Clean. Prod. 2018, 172, 2667–2682. [CrossRef]\n12. Freeman, R.E.E.; McVea, J. A Stakeholder Approach to Strategic Management; University of Virginia: Charlottesville, VA, USA, 2005; Volume 1.\n13. Sroufe, R. Integration and organizational change towards sustainability. J. Clean. Prod. 2017, 162, 315–329. [CrossRef]\n\nPublisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\n© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/)."
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 153, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 196570, Requested 7128. Please try again in 1.109s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 196570, Requested 7128. Please try again in 1.109s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": ", is strongly influenced by environmental performance, where the effect is positive. The relationship between environmental performance and financial performance can be observed in terms of income and costs. From the income side, it can be explained that consumer preference for consumer-oriented products allows these companies to enjoy market differentiation, competitive advantages, and consumers have a tendency to be willing to pay higher prices for environmentally-oriented products (premium prices). On the cost side, there are many benefits that\n\n# Journal of Asian Finance, Economics and Business Vol 7 No 12 (2020) 731–738\n\nI Dewa Made ENDIANA, Ni Luh Gd Mahayu DICRIYANI, Md Santana Putra ADIYADNYA, I Putu Mega Juli Semara PUTRA\n\nCompanies get as a result of increasing efficiency, avoiding potential liabilities, being better positioned to meet or exceed standards, and creating entry barriers for potential competitors. Thus, it can be explained through disclosure of environmental costs, that it will reflect the business ethics carried out by the company, as well as responsible management of resources. This will increase the social trust of stakeholders such as the public and consumers, which in turn will be able to improve financial performance, such as achieving maximum company profitability. According to Dutta et al. (2019) stated that green accounting issues relate to corporate profitability.\n\n# H2: The implementation of green accounting is able to improve the financial performance.\n\n# 2.6. Corporate Sustainability Management System (CSMS) in Financial Performance\n\nWhen integrating the concept of sustainability, the company should develop management models and strategies that will lead to the creation of social, environmental and economic values. It is necessary to set up corporate governance, which incorporates a positive response to the company’s social, economic and environmental risks and opportunities that have a potential to influence performance of the organization.\n\n# H3: Implementing a CMS can improve financial performance.\n\n# 3. Research Methodology\n\nThe population in this study was 154 companies listed on the Indonesia Stock Exchange (BEI) for the 2018-2019 period. This study took a sample of publicly-traded companies listed on the Indonesia Stock Exchange that participated in the Company Performance Rating Program in Environmental Management (PROPER) for 2018-2019. Purposive sampling was used, so a research sample of 38 companies was selected. The data analysis tool uses the Structural Equation Modeling (SEM) approach, known as the Partial Least Square (PLS) method. The currently drawn sample fulfills the required characteristics. In general, these characteristics are as follows:\n\n1. The sample companies engaged in manufacturing that go public and are listed on the Indonesia Stock Exchange and publish financial reports (annual reports) in 2018-2019.\n2. The companies selected as samples were manufacturing companies that participated in the Company Performance Rating Program in Environmental Management for 2018-2019.\n\nThe number of samples of PROPER companies in the period 2018 to 2019 was 38 companies, so that the number of observations was 76, as shown in the following table.\n\n# Table 1: Purposive Sampling\n\n|No|Description|Total|\n|---|---|---|\n|1|Number of Manufacturing Companies listed on the IDX for the 2018-2019 Period Companies whose financial statements are incompletely available for the 2018-2019 period|154|\n|2|Manufacturing companies that do not participate in the ranking assessment program in environmental management successively 2018-2019|(116)|\n|Total of sample|Total of sample|38|\n\n# 3.1. Green Accounting\n\nGreen accounting is the company’s performance in creating a good (green) environment. Green accounting companies are measured by the company’s achievements in participating in the PROPER program, which is one of the efforts undertaken by the Ministry of Environment (KLH) to encourage corporate governance in environmental management through information instruments. The PROPER performance rating system includes the ranking of companies in five colors, which will be scored consecutively with the highest score of 5 for gold and the lowest score of 1 for black.\n\n# 3.2. Corporate Sustainability Management System (CSMS)\n\nBased on Dočekalová and Kocmanová (2016), the measurement of corporate sustainability is using Complex Performance Indicator (CPI). CPI integrates the environmental, social, economic and corporate governance performance of the company. CPI contains seventeen key performance indicators, which were determined from the basic set of performance indicators using statistical methods. CPI sums up the complex corporate performance into a single value, but, at the same time, the set of aggregated sub-indicators of individual performance areas enables a detailed analysis and determination of the impact of various performance areas and factors on the complex corporate performance. Figure 1 visualizes the scheme of composite corporate performance indicator - Complex Performance Indicator.\n\n# I Dewa Made ENDIANA, Ni Luh Gd Mahayu DICRIYANI, Md Santana Putra ADIYADNYA, I Putu Mega Juli Semara PUTRA\n\n# Journal of Asian Finance, Economics and Business Vol 7 No 12 (2020) 731–738\n\n# 4. Research Results and Discussion\n\n# 4.1. Research Results\n\nBased on the results of mediation analysis using PLS warp the following results are obtained: The summary of the modeling test results is shown in Table 2.\n\nThe results of the fit model and quality indices in Table 2 indicate that the research model meets all the conditions for fit from the research model, so that it is suitable for use in explaining the population.\n\n# 3.3. Financial Performance\n\nPerformance is the relative performance of the company in a similar industry, which is indicated by the company’s annual return. The company’s financial performance is the result of many individual decisions made continuously"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 153, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194052, Requested 6622. Please try again in 202ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194052, Requested 6622. Please try again in 202ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "0.704| | |\n|EGC|0.581|0.670| |\n|GSV|0.409|0.539|0.654|\n\nHenseler, Ringle, and Sarstedt [89] pointed out that the effect of the original Fornell and Larcker [88] discriminant validity test may be overestimated. Hence, this study further uses average heterotrait-monotrait (HTMT) to calculate the correlation ratio between the four facets of EEP, EGC, GSV, and GPPO. The overall result shows that it meets the standard value (all less than 0.85), so this study has good discriminative validity (see Table 4). A construct’s convergent validity is acceptable if its AVE is greater than 0.5. The AVEs of GSV, GPPO, EGC, and EEP were 0.688, 0.726, 0.736, and 0.628, respectively, which are greater than 0.5. Thus, the constructs considered in this study had suitable convergent validity. Besides, Bagozzi and Yi [90] pointed out that the R-square of the observation variable is >0.5, which means that each observation variable is suitable for measuring each potential variable (Table 3). The aforementioned results indicated that the measurements in this study had acceptable validity and reliability.\n\n# 4.2. Structural Model Results\n\nThe analysis of moment structure and structural equation modeling were performed to test the research hypotheses. The structural modeling results are presented in Figure 3. According to the results, the full model had an acceptable fit (NFI = 0.951, CFI = 0.968, GFI = 0.928, and RMSEA = 0.061). GSV exhibited direct effects on EGC (p &lt; 0.001, standardized direct effect = −0.504), EEP (p &lt; 0.01, standardized direct effect = 0.148; Figure 3), and GPPO (p &lt; 0.001, standardized direct effect = 0.426). GPPO exhibited direct effects on EGC (p &lt; 0.001, standardized direct effect = −0.37) and EEP (p &lt; 0.001, standardized direct effect = 0.452). Moreover, EGC exhibited a direct effect on EEP (p &lt; 0.001, standardized direct effect = −0.307). The study results indicated that H1, H3, H4, H5, and H7 were supported. Thus, GSV has a direct and positive effect on GPPO, EGC, and EEP. GPPO has a direct and significant relationship with EGC and EEP, and EGC has a direct effect on EEP. According to Baron and Kenny [91], who verified the mediating effects, GPPO partially mediates the relationships of GSV with EGC and EEP.\n\n|EGCO2|EGCO}|EGC04| | | |\n|---|---|---|---|---|---|\n| |EGCOI|0.875|0.881\"|0.837\"|EGCOS|\n| | |0.8397|EGCO6|0.856| |\n| |0.859\"\"|Employee green confusion (EGC)| | | |\n|GSTO1|GSVO2|0.504-|HI|GPPOO2| |\n|6|-0.370|0.7480/765\"|0.882\"|H4| |\n|GPPOO1|H30.426\"|0.86|Green Product|Psychological Ownership| |\n|H7|-0.307|0.895|0.8137|F6| |\n|H5|0.898'|H2|b|0.148| |\n|GPPOO}|0.4527|Employee environmental performance (EEP)| | | |\n|EEPO1| |0.811|0.818|0.753\"| |\n|EEPO2| |EEPO3|EEPO4| | |\n\nChi-square/df = 2.764, GFI 0.928, RMSEA 0.061, NFI 0.951, and CFI 0.968. Note: p &lt; 0.01, and p &lt; 0.001.\n\nFigure 3. Full model results.\n\nTo ensure preciseness, we performed a percentile bootstrap procedure and a deviation correction percentile bootstrap procedure 5000 times with a 95% confidence interval to examine two mediating models [92]. According to the advice of Preacher and Hayes [93], we calculated the confidence interval of the upper and lower bounds to verify whether the indirect effects were significant. The bootstrap test results presented in Table 5 indicated that GPPO partially mediated the relationship between GSV and EGC (standard indirect effect = −0.145, Z = 4.394, p &lt; 0.001; 0 was not included in the 95% confidence interval) and between GSV and EEP (standard indirect effect = 0.141, Z = 4.7, p &lt; 0.001; 0 was not included in the 95% confidence interval). Thus, hypotheses 6a and 6b were confirmed. After exploring the indirect effects of the variables of the structural model, we further examined the obtained data and found two unexpected intermediary relationships: (1) the mediation effect of EGC on the relationship between GSV and EEP (standard indirect effect = 0.113, Z = 2.216, Z &gt;"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197844, Requested 7853. Please try again in 1.709s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197844, Requested 7853. Please try again in 1.709s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "water and energy consumption. It is a pioneering innovator in environmental approaches; it was recognized as a leader in environmental protection by the United States Agency for Environmental Protection and has been ISO14001 certified since 1997, with one of the earliest certifications in the world.\n\nThe manufacturing company wishes to evaluate its current and potential suppliers before choosing them for partnering. The company considers key factors affecting the sourcing functional efficiencies. The supplier is also evaluated and chosen using various sustainability criteria as part of the strategic organizational goal to achieve a sustainable competitive advantage. Currently, the company has two suppliers, identified as S1 and S2. It has also another potential supplier, S3.\n\nThe study was conducted between September 2019 and February 2020. We started by a face-to-face meeting with different managers including a purchasing manager (DM1), a logistics manager (DM2) and a supply chain director (DM3) in the company under study. The objective of this meeting was first to better understand the problem and to validate the criteria found in the literature for the supplier selection problem with experts. Later, the same three decision-makers participated in each stage.\n\nThus, in the AHP stage, the three DMs in the company concerned was asked to answer a questionnaire including all possible pairwise comparisons for criteria. The questionnaire was presented in an Excel worksheet and sent by email for managers DM1, DM2, DM3. They jointly completed the questionnaire of the possible pairwise comparisons as they wanted to prioritize the criteria in the same way, so that they agreed on the preferences of the criteria. Thus, no aggregation was required for data at this stage. Then, we obtained matrix results and priority weights for evaluation criteria.\n\n# Sustainability 2020, 12, 10584\n\n# Defining sustainability selection criteria\n\n# Initial evaluation of criteria and Causal diagram\n\n# Step 1. Modelling hierarchical structure\n\n# Step 2. Constructing the judgment matrix\n\n# Step 3. Computing the vector of criteria weights\n\n# Step 1. Constructing the initial relationship matrices\n\n# Step 2. Calculating the total relation matrix\n\n# Calculating the average matrix\n\n# Step 4\n\n# Step 3. Calculating the total given and joint direct and indirect effects\n\n# Step 5. Producing causal and effect diagram\n\n# Defining states and parametrizing the Bayesian network model\n\n# Parametrizing sustainable aspects nodes\n\n# Parametrizing criteria nodes\n\n# Completing sensitivity analysis\n\n# Analyzing sensitivity of evidence with tornado graphs\n\n# Analyzing 'what if' scenarios\n\n# Using the proposed Bayesian network model\n\nFigure 1. Graphical representation of multi-stage hybrid decision support methodology using AHP-DEMATEL-BN.\n\nNext, in the DEMATEL stage, we sent by email also a questionnaire as an Excel worksheet for the three managers. Each decision-maker was asked to evaluate the direct influence of criterion “ci” on criterion “cj” using a linguistic scale. In order to aggregate the data from the three managers, the DEMATEL method was proposed to calculate the average matrix. Then, the sums of total effects and the net affect among all criteria are calculated.\n\nSustainability 2020, 12, 10584 7 of 23\n\nThen, in the BN stage, we conducted first a meeting by video conference with the three managers in order to introduce the causal graph and the ordinal states (very low, low, medium, high and very high) that could be allocated for each criterion. These ranges were determined using feedback from three case company managers which were specific to their organization.\n\nThen, decision-makers participated together a meeting and sent us by email data for case suppliers S1, S2 and S3, as a summary of their judgments regarding potential suppliers according to each criterion that was used as principal input in the BN model.\n\nDuring the whole period, we also made intermediate online calls in order to present and discuss the results of each work package stage with the three decision-makers.\n\nThen, the different steps of the proposed approach are explained through this case study.\n\n# 3.1. Defining Sustainability Selection Criteria\n\nThis step is significant because a correctly identified set of criteria plays a vital role in supporting the decision-making process [6]. We define the criteria under economic (Eco), environmental (Env) and social dimensions (Soc) based on the literature review and the opinion of the decision-makers of the company. Thus, key decision criteria are investigated from a comprehensive literature review [5,9,15,25]. Then, these criteria are validated with decision-makers as an initial step in the sustainable supplier selection process. Criteria are defined as follows:\n\n- Overall costs (Eco1): This is a key criterion for evaluating a supplier because it dictates the total supply chain cost. This criterion includes transportation and purchasing costs.\n- Quality of product (Eco2): This is the capability of products and material to meet the quality standards for production processes. Scrap rate is used to determine the quality of delivered parts in this study.\n- Quality of service (Eco3): This criterion represents the ability of a partner to satisfy demand and perform various functions in terms of delivery.\n- Reducing pollution (Env1): The total emitted CO2 by each supplier is used to determine their performance regarding reducing pollution.\n- Resource consumption (Env2): Suppliers are evaluated regarding the amount of energy consumption. Building energy performance indicator in kwh/m2/year is used.\n- Environmental management system (Env3): The level of effort to reduce environmental impact is measured by an environmental management system certification (ISO 14001) (https://nbs.net/p/3-ways-smes-can-tackle-iso-14001-70c12e6b-8c15-428b-9c15-c248f08cf098). ISO 14001 has a progressive approach that breaks down the certification process into three"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 193062, Requested 7720. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 193062, Requested 7720. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "’ achievement behaviors are affected by expectations and values [48], which results in individuals investing increased efforts to obtain expected values [49 ]. When a company develops a suitable GSV, the GSV motivates employees to strive for goals and values that contribute to employee behavior. Related research has indicated that a shared vision is crucial for enhancing employee environmental behavior [24,34,35,50]. Consequently, the following hypothesis is proposed:\n\n# Hypothesis 2 (H2). GSV is positively associated with EEP.\n\n# 2.3. Effects of Green Product Psychological Ownership (GPPO)\n\nPsychological Ownership (PO) refers to the relationship between a person and an object that is closely connected with the self [ 51 ]. The concept of ownership is partially based on the research of consumer behavior regarding the extended self and possession [ 52 ,53 ]. Isaacs [ 54 ] indicated that the thoughts in a person’s mind become a part of them. For an individual, when property is accepted in the mind, it becomes “mine” [55]. Legal ownership can provide an opportunity for individuals to assimilate themselves into a company and become part of it, which can enhance the emergence of ownership as a mental status [56]. Because ownership connects possessors to targets, when employees link work with emotion, their connection with the work becomes closer. Furthermore, positive attitudes and thoughts are generated to further promote work performance [57 ]. Ownership is a mental status experienced by humans in which people consider themselves to own a target (nonmaterial or material in nature) completely or partially [ 58]. According to Pierce et al. [58 ], PO refers to a personal sense of possession held by an individual for an immaterial or material object (“this is mine!”). Due to PO, an individual is willing to take responsibility or sacrifice for their organization [59].\n\nFor the sustainable development of an enterprise, the degree of PO of company members for their company’s green products affects their behavior and attitude as well as the company’s green management performance. GPPO occurs when a company member has a psychological sense of ownership for the company’s green products, treats the products as subject matter, generates positive attitudes and thoughts, and is willing to engage in off-role behavior and take risks for this behavior such as dedication and sacrifice [ 35 ]. Therefore, for companies that are moving toward sustainable development, the degree of GPPO affects employees’ behavior, attitudes, and organizational green management performance. Furthermore, when a company employee has strong GPPO, they would exhibit a positive attitude and positive ideas, be willing to take risks for the company, and make additional efforts and sacrifices [35].\n\n# 2.3.1. Positive Effects of Green Shared Vision (GSV) on Green Product Psychological Ownership (GPPO)\n\nPersonal PO in organizations mainly originates from the four motivations of human needs: (1) Efficacy and effectance, (2) self-identity, (3) having a place, and (4) stimulation. Of these motivations, stimulation needs are incentives for PO. Efficacy and effectance indicate that individuals can successfully\n\n# Sustainability 2020, 12, 10514\n\nexercise control and appear to have a sense of ownership, which is used as a source of attaining satisfaction. Self-Identity represents the personal experience of biasing the subject matter, and as a part of self-extension, the most important thing is to own. Such holdings symbolize a kind of identity and are interpreted by others. Having a place refers to the need for personal space, which motivates individuals to control their surroundings and invest in them. Stimulation drives individuals to use, care about, and maintain objects. Thus, people are motivated to achieve stimulating needs and meet awakening requirements [58–61].\n\nMany factors influence the formation of PO. These factors influence not only the formation of PO and work characteristics but also the company culture, attitude of high-level managers, company’s goals and vision, and reputation of the company [62]. A common vision conveys an organization’s members’ common goals and ambitions for the organization [29, 63]. Moreover, it represents the organization’s vision, mission, and core values [64, 65]. Thus, when a company promotes sustainable development and formulates a GSV, this expresses to employees the goal and value of their efforts and strengthens their personal ownership and PO of the target green product. Chiu et al. [62] proposed that a company’s goals and vision affect PO. Moreover, according to Chang [35], GSV contributes to GPPO. Therefore, we propose the following hypothesis:\n\n# Hypothesis 3 (H3).\n\nGSV is positively associated with GPPO.\n\n# 2.3.2. Effect of Green Product Psychological Ownership (GPPO) on Employee Green Confusion (EGC) and Employee Environmental Performance (EEP)\n\nPO affects individuals’ attitudes, motivations, and behaviors. Furthermore, PO causes a person to exhibit a stance, sense of responsibility, and self-concept beyond the norms [66]. When an organization’s members have PO for their organization, they tend to exhibit more responsibility for their roles, take greater care of the organization, and adopt a protective attitude toward the organization [67]. Moreover, they may be willing to take risks or make personal sacrifices for the organization [59] and the subject matter of PO [59]. When members of an organization have PO for a certain subject matter, they may exhibit positive attitudes toward the organization [68]. Research has indicated that PO is an important predictor of the status of members of organizations [56, 58, 66, 69, 70]. Studies have indicated that factors such as the work performance and satisfaction of work can be predicted by organization-based PO [58, 59, 71, 72].\n\nThe PO of green products can predict individuals’ organizational citizenship behavior for the environment [35]. When PO is assigned to a"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 192744, Requested 7903. Please try again in 194ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 192744, Requested 7903. Please try again in 194ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "effect of organizational members’ psychological processes on the organization’s environmental management performance [1, 20 – 26]. This study investigated the effect of GSV on GPPO, EGC, and EEP by focusing on company staff and using psychological ownership (PO) theory and expected price theory. We used the obtained findings to fill the research gap on EGC issues in corporate sustainability research. This study proposes a comprehensive conceptual structure to explore the effect of company members’ psychological processes regarding the company’s green issues on the company’s green management performance.\n\n# Figure 1. Integrated conceptual structure.\n\n|Psychological Processes of Green Issues|Green Management Performance|\n|---|---|\n|Motivation|Green Employee Behavior and Performance|\n|Green Shared Vision|Green Employee Confusion|\n|Green Product Psychology|Employee Environmental Performance|\n|Psychological Ownership| |\n\n# 2. Literature Review and Hypothesis Development\n\n# 2.1. Negative Effects of Green Shared Vision (GSV) on Employee Green Confusion (EGC)\n\nGiven the global trend of concern for environmental issues, existing strict environmental regulations, and customers’ perception of the environment, companies must develop suitable legal strategies to gain valuable resources [27, 28]. A collective strategic direction can be encapsulated in a shared vision, which guides company members’ actions according to a certain approach [29]. A shared vision can also be used to encourage corporate employees to exhibit excellent performance [30]. A shared vision is a key aspect of strategic management for a company because it indicates the unique objective, general direction, and practices of the company [31]. The method used by an organization to develop a shared vision has become the primary focus of environmental management research. The concept of GSV is defined on the basis of environmental friendliness and sustainable development [24]. Managers establish clear and common environmental goals for future organizational development, which enables the organization to supervise the green behavior and performance of employees as well as minimize EGC.\n\nStaff confusion may occur when a company provides excessively similar, excessively complex, or an excessive amount of product or service information regarding SDGs. The larger the amount of information processed by an individual, the higher is their likelihood of experiencing information overload [32]. Information overload creates confusion [33], and EGC may affect a company’s SDGs. This research refers to the definition of EGC provided by Chen and Chang [18], who stated that EGC refers to employees’ inability to correctly understand the environmental characteristics of their company’s products and services as well as the characteristics of its environmental policy during information processing. Therefore, companies must formulate a clear green common vision and effectively obtain employee recognition to encourage the green behavior and performance of employees [24, 34, 35]. GSV can encourage the green behavior and performance of employees, effectively develop employee recognition, and eliminate EGC. GSV is negatively related to EGC. Therefore, the following hypothesis is proposed:\n\nHypothesis 1 (H1). GSV is negatively associated with EGC.\n\n# 2.2. Positive Effects of Green Shared Vision (GSV) on Employee Environmental Performance (EEP)\n\nCurrently, many companies are facing challenges caused by the rise of global environmental awareness, increasingly stringent environmental regulations, and increasing consumer environmental awareness. To ensure that valuable resources are obtained legally, an organization must formulate a suitable legal strategy [27, 28]. A carefully planned and designed company vision facilitates employees’ actions and decisions and inspires them to move toward a shared vision [36]. A shared vision is a common future goal set by an organization’s manager for the development of the organization. It conveys the norms and beliefs of the company to members. A shared vision can motivate employees to perform [30] and exceed expectations related to their work performance [34].\n\nWhen an organization proactively performs environmental actions, its long-term goals with respect to corporate greening are conveyed to its staff [37]. Environmental improvement performance depends on whether a shared vision exists between staff and managers, especially when environmental strategies require intensive staff engagement [38]. Above all, the process of combining corporate environmental performance and strategy is profoundly affected by the shared vision [39]. A shared vision can reduce the adverse effects caused by senior team members setting different goals and having conflicting views [40, 41]. Moreover, such a vision can prevent the fragmentation of a team.\n\nTeam members must establish a shared vision, and continual interaction, practice, and reflection can improve team performance [42]. With regard to EEP, organization managers can influence green purchasing behavior [43], promote environmental market-oriented strategies [44], and encourage\n\n# Sustainability 2020, 12, 10514\n\nemployees to have a responsible attitude toward environmental issues [ 45 ]. Organizations should always encourage members who possess good intentions, especially those who adopt a responsible attitude toward environmental issues. This step would enable employees to perform responsible actions when environmental problems arise.\n\nEmployees play an important role in promoting green management in an enterprise. Paillé and Meija-Morelos [ 46 ] defined EEP as the performance of employees’ compliance with company norms, and their interaction and communication based on personal environmental knowledge to relevant stakeholders. Expectancy–valence theory is a cognitive motivation theory that connects the energy of an individual’s motivation or willingness to strive for goals and expectations and obtain the expected value of the incentives to a specific purpose [47].\n\nAccording to expectancy–valence theory, the choice, performance, and continuity of organization members’ achievement behaviors are affected by expectations and values [48], which results in individuals investing increased efforts to obtain expected values [49 ]. When a company develops a suitable GSV, the GSV motivates employees to strive for goals and values that contribute to employee behavior. Related research has indicated that a shared vision is crucial for enhancing employee environmental behavior [24,34,35,50]. Consequently, the following hypothesis is proposed:\n\n# Hypothesis 2 (H2). GSV is positively associated"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197647, Requested 8172. Please try again in 1.745s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197647, Requested 8172. Please try again in 1.745s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "# Corporate Sustainability: It’s Mine! Effect of Green Product Psychological Ownership on the Environmental Behavior and Performance of Employees\n\nTai-Wei Chang 1, Kuo-Hsuan Wang 2 and Yi-Hsiung Lin 2,3\n\n1 Graduate School of Resources Management and Decision Science, National Defense University, Taipei 112, Taiwan\n\n2 Department of Business Administration, National Taipei University, New Taipei City 237, Taiwan; kingwang@itri.org.tw (K.-H.W.); yhlin.e1@msa.hinet.net (Y.-H.L.)\n\n3 Management College, National Defense University, Taipei 112, Taiwan\n\n* Correspondence: allain1105@yahoo.com.tw\n\nReceived: 14 November 2020; Accepted: 12 December 2020; Published: 15 December 2020\n\n# Abstract\n\nGreen shared vision (GSV) has provided a research prototype for past green management research topics; however, few studies have examined the confusion related to environmental issues among employees. Therefore, to fill the aforementioned research gap, this study used psychological ownership theory and expectancy–valence theory to establish a research framework for GSV. This study explored the relationships of GSV with employee green confusion (EGC) and employee environmental performance (EEP) as well as the mediating effect of green product psychological ownership (GPPO) on these relationships. The research results indicate that GSV positively affects GPPO, EGC, and EEP. Moreover, GSV also influences behavior and performance through personal psychological processes. Thus, if an enterprise wishes to establish GSV, it must adopt a series of supporting measures, including improving members’ GPPO, to effectively reduce EGC and improve EEP to realize the goal of sustainable development.\n\n# Keywords\n\ngreen shared vision; psychological ownership theory; green product psychological ownership; employee green confusion; employee environmental performance\n\n# 1. Introduction\n\nCorporate strategies worldwide are affected by environmental management issues [1]. When enterprises support environmental protection and actively participate in environmental management, they not only pursue corporate values but also improve their image by complying with environmental regulations [2]. Enterprises should embrace the philosophy of sustainability with a creative mind in this environmentalistic age [3, 4]. In general, shared visions are developed at the organizational, group, or individual levels to generate motivation for achieving transformation from a present status to a desirable end status [5]. When the organizational planner has a strong vision, the sustainable development of a company is promoted [6]. Obtaining a better understanding of the driving forces behind the phenomena might help new companies to integrate resources and enhance their corporate performance [7]. A corporate shared vision is a key factor affecting the competitive advantage of a corporation over other entities. Currently, sustainable development has become an important issue worldwide. The pursuit and achievement of sustainable development goals (SDGs) has become a trend for companies. Therefore, corporate sustainability has become a major topic.\n\nSustainability 2020, 12, 10514; doi:10.3390/su122410514 www.mdpi.com/journal/sustainability\n\n# Sustainability 2020, 12, 10514\n\nCorporate sustainability refers to decreasing the waste of natural resources (especially nonrenewable resources) to zero during enterprise operational activities to reduce the damage caused by corporate activities on society or the environment [8]. Corporate sustainability has become an indispensable strategy for many companies today [9 – 11]. Such strategies are gradually being integrated into company activities and culture, whether with respect to the corporate system (including operations), strategies, organizational systems, or stakeholders (internal and external as well as social and environmental) [12]. Corporate sustainability has become the basis of sustainable success [13]. When employees and organizations have different values, implementing a developed sustainability plan is difficult [14]. Employees are the core resource of an enterprise [15]. Employees play an important role in maintaining the competitive advantage of an organization. They also determine the performance of the organization [16]. A company’s ability to achieve a competitive advantage is related to its ability to employ excellent talent [17].\n\nGiven the aforementioned information, employees play an important role when designing sustainable development strategies for an enterprise. The occurrence of employee green confusion (EGC) cannot be ruled out when employees promote green shared vision (GSV). However, studies on green confusion have not focused on the views of an enterprise’s employees. Most of these studies have examined consumer orientation and have focused on the effects of greenwash on consumers, such as the effects of greenwash on green consumer confusion and green trust [18] as well as environmental and product perceptions [19]. Thus, employee orientation related to confusion in the field of corporate sustainability has been rarely discussed. To fill this research gap, the present study proposes a new concept called EGC. This study refers to the definition of Chen and Chang [18] to define EGC as the confusion of employees regarding the environmental characteristics of company products or services. The present study developed an integral framework of employee environmental performance (EEP). It also investigated the relationships of GSV with EGC and EEP as well as the mediating effects of green product psychological ownership (GPPO) on these relationships. Environmentalism is an important corporate issue today, and EEP is critical to corporate sustainability. This research enables a better understanding of the effects of a shared vision and various types of integration on corporate management.\n\nStudies have rarely used a theoretical basis to explore the effect of organizational members’ psychological processes on the organization’s environmental management performance [1, 20 – 26]. This study investigated the effect of GSV on GPPO, EGC, and EEP by focusing on company staff and using psychological ownership (PO) theory and expected price theory. We used the obtained findings to fill the research gap on EGC issues in corporate sustainability research. This study proposes a comprehensive conceptual structure to explore the effect of company members’ psychological processes regarding the company’s green"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 196222, Requested 7884. Please try again in 1.231s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 196222, Requested 7884. Please try again in 1.231s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": ", they may exhibit positive attitudes toward the organization [68]. Research has indicated that PO is an important predictor of the status of members of organizations [56, 58, 66, 69, 70]. Studies have indicated that factors such as the work performance and satisfaction of work can be predicted by organization-based PO [58, 59, 71, 72].\n\nThe PO of green products can predict individuals’ organizational citizenship behavior for the environment [35]. When PO is assigned to a certain subject matter, employees tend to regard it as a social entity, be psychologically related to it, be willing to take risks for it, and generate positive attitudes and behaviors toward it. In general, according to PO theory, GPPO refers to the PO generated by employees of a company for its green products when they regard the products as a subject matter. GPPO enables a company’s employees to exhibit positive attitudes and behaviors, and this contributes to organizational performance and encourages employees to actively search for information regarding company products, services, and related environmental policies that they did not understand initially. To maintain GPPO, employees become more willing to follow relevant environmental regulations and practices. Therefore, this study proposes the following hypotheses:\n\n# Hypothesis 4 (H4).\n\nGPPO is negatively associated with EGC.\n\n# Hypothesis 5 (H5).\n\nGPPO is positively associated with EEP.\n\n# 2.3.3. Mediating Effects of Green Product Psychological Ownership (GPPO)\n\nPO differs according to the motivation for possession. The feeling of possession is ubiquitous. Possession can be a tangible goal, an intangible goal, or a statutory but not legal form of ownership [73].\n\n# Sustainability 2020, 12, 10514\n\n# 6 of 19\n\nWhen the inner and psychological feelings possessed by an individual are integrated, and the members of the organization will be based on human instinct motivation, they may feel such ownership due to various factors in the organization and practice to further satisfy. In particular, when the target slowly becomes a part of the owner’s psychological identification, PO is generated [58].\n\nAccording to PO theory, an individual’s PO of a certain subject matter originates from four demand motivations that include (1) efficacy and effectance, (2) self-identity, (3) having a place, and (4) stimulation [58 –61]. The psychological history of PO as well as the personal positive behaviors and attitudes are based on interpretations of the subject of PO. According to the theoretical perspective of expectation motivation, an individual’s positive performance and contribution are related to the desire to meet expectations [48, 49]. Consequently, when the underlying motivation of an individual’s PO meets the expected value, the individual would exhibit a highly positive behavior and attitude. Therefore, the following hypotheses are proposed:\n\n# Hypothesis 6a (H6a).\n\nThe relationship between the exposure to EGC and GSV is mediated by GPPO.\n\n# Hypothesis 6b (H6b).\n\nThe relationship between the exposure to EEP and GSV is mediated by GPPO.\n\n# 2.4. Negative Effects of Employee Green Confusion (EGC) on Employee Environmental Performance (EEP)\n\nCompanies are facing considerable pressure from relevant stakeholders, such as customers, business partners, and environmental organizations, to focus their policies on the environment [74] and develop, produce, and sell environmentally friendly products. Companies intending to achieve the goal of sustainable development may do well to formulate a GSV to promote all aspects of relevant environmental protection measures to create a green image of themselves [75 – 79]. Employees may experience information overload when an enterprise manager releases excessive information regarding the enterprise’s environmental regulations, products, or services to quickly respond to requests from relevant stakeholders, such as customers, environmental organizations, and governments.\n\nMitchell, Walsh, and Yamin [32] indicated that people exhibit different levels of information cognition and digestion when they process information. When the amount of information increases, the likelihood of information overload also increases. The release of a large amount of information can cause confusion among employees [32, 33] as well as make it difficult for employees to focus on the relevant environmental regulations promoted by the company and to interactively exchange environmental knowledge with relevant stakeholders. The aforementioned phenomenon of employee confusion is called EGC. When EGC occurs, employees’ interactions with their organization’s relevant norms and stakeholders are affected. Therefore, we propose the following hypothesis:\n\n# Hypothesis 7 (H7).\n\nEGC is negatively associated with EEP.\n\nThe research framework is illustrated in Figure 2.\n\n# Sustainability 2020, 12, 10514\n\n# Employee Green Confusion (EGC)\n\n# Green Shared Vision (GSV)\n\n# Psychological Ownership (GPPO)\n\n# Employee Environmental Performance (EEP)\n\n# Figure 2. Research framework.\n\n# 3. Methodology and Measurement\n\n# 3.1. Data Collection and Sample\n\nTo verify the aforementioned hypotheses in the Taiwan production industry, a questionnaire survey was conducted. The study participants were staff members who worked in the information services, electronics, components manufacturing, computer and peripheral products, health care and biotech, communication equipment manufacturing, electronic products and components, equipment and machinery manufacturing, and software industries in Taiwan. The questionnaire survey sample was randomly selected from the “Business Directory of Taiwan.” The participants were leaders or managers of the manufacturing, research and development, environment, or marketing departments or members of environmental product development projects. To ensure a high degree of content validity in this research, two rounds of pretests were conducted.\n\nRespondents from different industries and sectors were recruited in this study because such recruitment reduces common method variance problems. To effectively improve the response rate, reliability, and validity of the questionnaire, before the questionnaire was issued, we contacted the relevant companies by phone to determine whether they provided green products or related services and confirmed whether green products were their primary"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 153, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 198526, Requested 7216. Please try again in 1.722s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 198526, Requested 7216. Please try again in 1.722s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "(2013) indicates that the rapid growth of these markets is significantly influenced by two essential pieces of legislation: the Company Law and the Securities Law, enacted in 1993 and 1998, respectively. The Company Law provides the legal requirement for the transformation of state-owned enterprises (SOEs) into private or listed enterprises. To conform to the two legislations, the stock exchanges in China have implemented guidelines for their listed corporations to take responsibility for their stakeholders. The SZSE issued the Corporate Social Responsibility (CSR) Guidelines for Listed Companies in 2006 and the SSE issued similar guidelines in 2008, and both stock exchanges begin to mandate CSR reporting in a subset of listed companies. However, the guidelines provide limited assistance to companies preparing for their disclosures. The lack of a prescribed reporting framework is, therefore, ambiguous and has led to large variations in reporting practice, such that users find the reports challenging to compare and use for decision-making (Zhang et al., 2015). In addition, sustainability information can be used for window-addressing and causes heterogeneous expectation among investors. The subsequent noise increases stock price volatility and decreases firm values (Orlitzky, 2013). Given the local community in China is in favour for CSD information, particularly under the sustainability promotional strategy by the state government, CSD reporting companies are likely to be inadequately guided by the existent guidelines and generating information that increases the dispersion of the market expectation. However, limited research has examined what is expected from primary stakeholders and how the reporting companies should address such expectations. As such, in this study, we focus on financial analysts’ perceived importance of CSD in the unique institutional setting of China.\n\n# 2. Literature review and hypotheses development\n\n# 2.1 The context of sustainability reporting in China\n\nSustainability reporting, which is also referred to as CSR reporting, focused solely on social issues at its very beginning stage in the early 1960s (Lin, 2010). Elkington (1994) suggested that there are six stages of CSD development, which include ignorance, awakening, denial, guilt reduction, displacement behaviour and tokenism, conversion and finally, integration. This was further extended and re-summarised by Dunphy et al. (2003). They developed more sophisticated concepts for each of the six stages of CSD development, which include rejection, non-responsiveness, compliance, efficiency, strategic proactivity and the sustaining corporation.\n\nAfter the emergence of triple bottom line reporting, the number of companies that issued CSD increased, with different names to show different areas of focus. Reynolds and Yuthas (2008) explained this early stage of reporting sustainability as companies owing the duty to the society in which they are bonded with a social contract.\n\nAccording to Freeman (1984), sustainability reporting is an approach for a company to identify its socially relevant behaviour, determine those to whom the company is accountable for its environmental and social performance and develop appropriate measures and reporting techniques. However, being sustainable or ecologically responsible is defined differently across cultures (Hofstede, 1980).\n\nIn China, CSD is mostly perceived to be a response to external government and public pressures on corporate management (Gao, 2009). The notion of corporate sustainability reporting was first proposed in 2006 in the amendment of the Company Law of the People’s Republic of China, Article 5 of the General Law. Later in 2006, in the Chinese Communist Party Sixth Plenary Session, a national plan proposal was made to create a harmonious Chinese society with a focus on being socially responsible, particularly for business enterprises (Gao, 2010).\n\nAs a response to the national plan, the SSE and SZSE issued social reporting guidelines in 2006 and 2008, respectively, to create an appropriate system for corporate sustainability reporting. According to the SSE guidelines Notice for Better Reporting 2008 Annual Reports, a subset of industries that were listed in the Chinese financial market, including the SSE corporate governance sector, firms with shares listed overseas and financial companies, were mandated to prepare CSR reports alongside the annual reports. However, despite the introductions of a number of policies after the two stock exchange markets announced their guidelines, the meaning and definition of corporate sustainability were never specified. The guidelines also did not provide any indication of how to prepare and what to include in a CSD. While the CSR guidelines in China have initiated systematics rule and approaches to report CSR, the coverage and the specificity of the reports are still less comprehensive than those formulated in the Western context (Nornha et al., 2013).\n\nThe board indications from the CSR guidelines in China are provided below:\n\n“Listed companies are encouraged to disclose non-financial information in CSR reports.\n\nNon-financial information should be based on the triple bottom line namely, economic, social and environmental information.\n\nCSR reports should be endorsed by the Board of Directors and the Audit Committee.\n\nAreas and circumstances in which listed companies should compulsorily disclose environmental information are indicated.\n\nA new concept of social contribution value per share (SCVPS), a ratio used to measure the listed companies.” (Nornha et al., 2013, p. 32)\n\nAs suggested further by Nornha et al. (2013), the reporting companies could choose their own methods to calculate the related ratio under the guidelines, which was subjective and challenging for companies to follow. While the concept of corporate sustainability has become more commonly accepted in China, there has been no agreed-upon definition of it. Therefore, the standardisation and the regulations of corporate sustainability in China are in a great need of development (Bai et al., 2015).\n\n# 2.2 Global Reporting Initiative (GRI) guidelines in China\n\nIn China, the GRI (2013) guidelines are used as the basis of most sustainability reportings. In recent decades, GRI has attempted to provide comprehensive"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194476, Requested 7176. Please try again in 495ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194476, Requested 7176. Please try again in 495ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "p &lt; 0.001; 0 was not included in the 95% confidence interval). Thus, hypotheses 6a and 6b were confirmed. After exploring the indirect effects of the variables of the structural model, we further examined the obtained data and found two unexpected intermediary relationships: (1) the mediation effect of EGC on the relationship between GSV and EEP (standard indirect effect = 0.113, Z = 2.216, Z &gt; 1.96; 0 is not included in the 95% confidence interval) and (2) the distal mediation effects: GSV and EEP via GPPO and EGC (standard indirect effect = 0.145, Z = 1.986, Z &gt; 1.96; 0 was not included in the 95% confidence interval).\n\n# Sustainability 2020, 12, 10514\n\n# 5. Conclusions and Implications\n\nIn this study, we investigated Taiwanese companies that engage in environmental protection. We examined the effect of psychological processes related to green issues on employees’ green management performance. This study verified the relationships among GSV, EEP, GPPO, and EGC through PO theory and expectancy–valence theory. By investigating GSV and the PO of green products, we came to understand the effect of psychological processes related to green issues. Green management performance is enhanced by reducing EGC and improving EEP.\n\nThe study results indicate the existence of associations in the concept of integration. For example, the psychological processes related to green issues affect EGC and EEP. In addition, this study indicates that the antecedents of PO strengthen the PO effect as well as the behaviors and attitudes of the parties. The combined insights obtained from PO theory and expected value theory can contribute to sustainable environmental development. The results indicate that GSV has a significant negative correlation with EGC and a significant positive correlation with EEP. Thus, developing a GSV for an enterprise is an important strategy for the enterprise to achieve sustainable development. GSV can strengthen the PO.\n\n# Table 5. Mediation results of GPPO and EGC when using a confidence interval bootstrap.\n\n|Path|Point Estimation|S.E.|Z|Lower|Upper|Lower|Upper|\n|---|---|---|---|---|---|---|---|\n|(1) GSV → GPPO → EGC|−0.145|0.033|4.394 ***|−0.226|−0.093|−0.217|−0.087|\n|(2) GSV → GPPO → EEP|0.141|0.030|4.7 ***|0.089|0.206|0.088|0.204|\n|(3) GSV → EGC → EEP|0.113|0.051|2.216 *|0.036|0.242|0.031|0.230|\n|(4) GSV → GPPO → EGC → EEP|0.035|0.015|2.333 *|0.013|0.075|0.010|0.069|\n|Total (1 + 2 + 3 + 4)|0.145|0.073|1.986 *|0.029|0.323|0.023|0.309|\n\n# Contrasts\n\n|Contrast|Point Estimation|S.E.|Z|Lower|Upper|Lower|Upper|\n|---|---|---|---|---|---|---|---|\n|(1)−(2)|0.027|0.063|0.429|−0.105|0.145|−0.102|0.150|\n|(2)−(3)|0.078|0.043|1.814|0.020|0.196|0.016|0.182|\n|(3)−(1)|−0.105|0.035|3 **|−0.105|−0.181|−0.182|−0.040|\n\nNotes: (1) Standardized estimation of 5000 bootstrap samples; (2) Contrasts: differences in the two indirect effects; (3) GSV = green shared vision, GPPO = green product psychological ownership, EGC = employee green confusion, and EEP = employee environmental performance; (4) ***: Z > 3.29, **: Z > 2.58, and *: Z > 1.96; and (5) N = 475.\n\n# Table 6. Results of the structural model.\n\n|Hypothesis|Path|Path Coefficient|Z Value|Results|\n|---|---|---|---|---|\n|H1|GSV→GPPO|0.426 ***| |H1 is supported|\n|H2|GSV→EGC|−0.504 ***| |H2 is supported|\n|H3|GSV→EEP|0.148 **| |H3 is supported|\n|H4|GPPO→EGC|−0.370 ***| |H4 is supported|\n|H5|GPPO→EEP|0.452 ***| |H5 is supported|\n|H6a|GSV→GPPO→EGC| |4.394###|H6a is supported (partial mediating)|\n|H6b|GSV→GPPO→EEP| |4.7###|H6b is supported (partial mediating)|\n|H7|EGC→EEP|−0.307 ***| |H7 is supported|\n|Study found|GSV→EGC→EEP| |2.216#|partial med"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 196158, Requested 7074. Please try again in 969ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 196158, Requested 7074. Please try again in 969ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "869|\n\n# References\n\n1. Chen, Y.S.; Chang, K.C. The nonlinear effect of green innovation on the corporate competitive advantage. Qual. Quant. 2013, 47, 271–286. [CrossRef]\n2. Teng, M.J. The effects of an environmental management system on intangible assets and corporate value: Evidence from Taiwan’s manufacturing firms. Asian Bus. Manag. 2011, 10, 381–404. [CrossRef]\n3. Chen, Y.S.; Chang, C.H. Enhance green purchase intentions: The roles of green perceived value, green perceived risk, and green trust. Manag. Decis. 2012, 50, 502–520. [CrossRef]\n4. Chen, Y.S. The drivers of green brand equity: Green brand image, green satisfaction, and green trust. J. Bus. Ethics 2010, 93, 307–319. [CrossRef]\n5. Boyatzis, R.E.; Rochford, K.; Taylor, S.N. The role of the positive emotional attractor in vision and shared vision: Toward effective leadership, relationships, and engagement. Front. Psychol. 2015, 6, 670–683. [CrossRef]\n6. Senbel, M. Leadership in sustainability planning: Propagating visions through empathic communication. J. Environ. Plan. Manag. 2015, 58, 464–481. [CrossRef]\n7. Chen, C.H. Effects of shared vision and integrations on entrepreneurial performance: Empirical analyses of 246 new Chinese ventures. Chin. Manag. Stud. 2015, 9, 150–175.\n8. Davenport, M.; Delport, M.; Blignaut, J.N.; Hichert, T.; Van der Burgh, G. Combining theory and wisdom in pragmatic, scenario-based decision support for sustainable development. J. Environ. Plan. Manag. 2019, 62, 692–716. [CrossRef]\n9. Ball, D.R. A Technology, Innovation, and Operations Strategic Model for Both Domestic and Global Sustainability. Int. J. Sustain. Soc. 2010, 5, 485–491.\n10. Corbett, L.M. Sustainable operations management: A typological approach. J. Ind. Eng. Manag. 2009, 2, 10–30. [CrossRef]\n11. Preston, L. Sustainability at Hewlett-Packard: From theory to practice. Calif. Manag. Rev. 2001, 43, 26–37. [CrossRef]\n12. Lozano, R. A holistic perspective on corporate sustainability drivers. Corp. Soc. Responsib. Environ. Manag. 2015, 22, 32–44. [CrossRef]\n13. Muradli, R.; Volkova, T. Strategic innovation application in creative industries in latvia. J. Bus. Manag. 2015, 10, 15–27.\n14. Avota, S.; McFadzean, E.; Peiseniece, L. Linking personal and organisational values and behaviour to corporate sustainability: A conceptual model. J. Bus. Manag. 2015, 10, 124–138.\n15. Drucker, P.F. The Practice of Management; Harper & Row: New York, NY, USA, 1954.\n16. Pfeffer, J. Competitive Advantage Through People: Unleashing the Power of the Work Force; HBS Press: Boston, MA, USA, 1994.\n17. Chuai, X.; Preece, D.; Iles, P. Is talent management just old wine in new bottles? Manag. Res. News 2008, 31, 901–911. [CrossRef]\n18. Chen, Y.S.; Chang, C.H. Greenwash and green trust: The mediation effects of green consumer confusion and green perceived risk. J. Bus. Ethics 2013, 114, 489–500. [CrossRef]\n19. Szabo, S.; Webster, J. Perceived Greenwashing: The Effects of Green Marketing on Environmental and Product Perceptions. J. Bus. Ethics 2020, 1–21. [CrossRef]\n20. Chen, Y.S. The positive effect of green intellectual capital on competitive advantages of firms. J. Bus. Ethics 2008, 77, 271–286. [CrossRef]\n21. Chen, Y.S.; Chang, C.H. The determinants of green product development performance: Green dynamic capabilities, green transformational leadership, and green creativity. J. Bus. Ethics 2013, 116, 107–119. [CrossRef]\n22. Chen, Y.S.; Chang, C.H. Enhance environmental commitments and green intangible assets toward green competitive advantages: An analysis of structural equation modeling (SEM). Qual. Quant. 2013, 47, 529–543. [CrossRef]\n23. Yeh, S.L.; Chen, Y.S.; Wu, S.S. The Obstacles and Solutions to the Corporate Social Responsibility Implementation in Taiwan. Int. J. Innov. Manag. Technol. 2014, 5, 266. [CrossRef]\n\n# Sustainability 2020, 12, 10514\n\n# References\n\n1. Chen, Y.S.; Chang, C.H.; Lin, Y.H. The determinants of green radical and incremental innovation performance: Green shared vision, green absorptive capacity, and green organizational ambidexterity. Sustainability 2014, 6, 7787–7806. [Cross"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 195560, Requested 7843. Please try again in 1.02s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 195560, Requested 7843. Please try again in 1.02s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "6a|GSV→GPPO→EGC| |4.394###|H6a is supported (partial mediating)|\n|H6b|GSV→GPPO→EEP| |4.7###|H6b is supported (partial mediating)|\n|H7|EGC→EEP|−0.307 ***| |H7 is supported|\n|Study found|GSV→EGC→EEP| |2.216#|partial mediating|\n\nNotes: (1) ***: p < 0.001, and **: p < 0.01. (2) ###: Z > 3.29, and #: Z > 1.96.\n\n# Sustainability 2020, 12, 10514\n\n# 5.1. Theoretical Implications\n\nOur research provides three academic contributions to the sustainable development of green management in the field of psychology. First, the empirical results verified the hypothesis that expectancy–valence theory incorporates PO. When results meet people’s expectations, they receive additional investment and compensation, strengthening the PO’s degree [49, 94]. The aforementioned contribution expands the original expected value theory to fields such as topic teaching and learning for young children [94–97], unemployment issues [47, 98], and physical and mental health issues [99], which enables research gaps in the field of business management to be filled. Moreover, few studies have examined confusion issues from the perspective of employees. Therefore, this study used the views of PO theory and expectancy–valence theory to establish a research framework for GSV to fill an existing research gap. Second, the empirical results of the past GSV research literature found that GSV contributes to employee’s proenvironmental behavior [100], green product development performance [34, 101, 102], and organizational citizenship behavior for the environment [35], especially focusing on employee behavior and product development performance. Finally, the study results indicate the effect of psychological process related to green issues on green management performance in an integrated conceptual framework. The expectation value theory and PO theory indicate that relationships exist among GSV, GPPO, EGC, and EEP. This finding expands the contribution of psychology to sustainable environmental development. This study also verified PO theory by examining the mediation effects of EGC and EEP on the relationship between GPPO and GSV. The results indicated that GSV enhances the degree of PO and positively affects GPPO. The research model expands the PO model and indicates that GSV is crucial for the formation of PO, reduces a company’s EGC, and improves a company’s EEP. Thus, GPPO is critical for corporate sustainability [35, 103].\n\n# 5.2. Practical Implications\n\nThe research findings can help Taiwanese companies promote environmental sustainability. These findings also provide a reference to other Asian companies seeking to perform green management. The research results indicate that a relationship exists between GSV and GPPO in psychological processes related to green issues. Moreover, the results indicate that an organization’s green management performance is affected by its EGC and EEP. This study indicates that EGC and EEP are caused by GSV and GPPO. GSV is positively correlated with EEP, GPPO is negatively correlated with EGC and positively correlated with EEP, and EGC is negatively correlated with EEP. The aforementioned results indicate that psychological processes related to green issues improve an organization’s green management performance. We found that employees’ EEP is affected by their EGC. Therefore, this study proposes several steps for corporate management to reduce EGC and promote EEP. First, the head of the enterprise management class should formulate a GSV, express the goals and aspirations of the company’s sustainable development, and regularly discuss and reflect on the amendments to the GSV. The development of a shared vision for the organization would improve organizational performance and motivate members to work toward organizational goal [29, 42, 63, 104, 105]. Thus, companies should use psychological processes related to green issues for verifying the execution results and adopt an active GSV strategy to create employee GPPO in their business models. By using the aforementioned strategy, companies can reduce employees’ EGC and improve their EEP. In particular, companies should formulate an environmental development blueprint and develop incentive plans to encourage their employees to participate in the design and production of environmental products. A good practice is for employees to participate in the production process of environmentally friendly.\n\n# 5.3. Limitations and Future Research\n\nThis study has certain limitations. First, the data analysis results unexpectedly revealed that EGC has a partial mediating effect on the relationship between GSV and EEP. The findings of this study provide preliminary concepts that should be verified using relevant studies. Second, this study analyzes the perspectives of expected value theory and psychological ownership theory and discusses the environmental behavior and performance of organizational employees. Future research can go further and use other theories. For example, the value theory can further strengthen the relationship between Psychological Processes of Green Issues and Green Management Performance through the exploration of Costs and benefits or the expectancy theory. Third, all the research participants were from Taiwan. The universality of the study results may be limited by differences in the national conditions, cultures, industrial scenarios, and economic structures between different countries. Therefore, the results of this study can be verified by conducting research in other countries and regions, such as Singapore, Japan, and South Korea. Finally, from the perspective of the company’s internal green management strategy, this study verifies that the psychological processes of company members related to green issues affect their GSV and GPPO. We also analyzed members’ environmental behavior and performance as well as excluding other behaviors and organizational characteristics that may disturb employees. In future research, we will be able to further explore the perceived organization’s support to the environment and the organization’s impact on the environment’s citizenship behavior [46]. Or, according"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 195559, Requested 7340. Please try again in 869ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 195559, Requested 7340. Please try again in 869ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "in adopting green purchasing standards in high-tech industrial firms. J. Bus. Res. 2012, 65, 951–959. [CrossRef]\n21. Rivera-Camino, J. Corporate environmental market responsiveness: A model of individual and organizational drivers. J. Bus. Res. 2012, 65, 402–411. [CrossRef]\n22. Paillé, P.; Raineri, N. Linking perceived corporate environmental policies and employees eco-initiatives: The influence of perceived organizational support and psychological contract breach. J. Bus. Res. 2015, 68, 2404–2411. [CrossRef]\n23. Paillé, P.; Meija-Morelos, J.H. Organisational support is not always enough to encourage employee environmental performance. The moderating role of exchange ideology. J. Clean. Prod. 2019, 220, 1061–1070. [CrossRef]\n\n# Sustainability 2020, 12, 10514\n\n# References\n\n1. Vansteenkiste, V.; Lens, W.; De Witte, H.; Feather, N.T. Understanding unemployed people’s job search behaviour, unemployment experience and well-being: A comparison of expectancy-value theory and self-determination theory. Br. J. Soc. Psychol. 2005, 44, 269–287. [CrossRef] [PubMed]\n2. Eccles, J.S.; Adler, T.F.; Futterman, R.; Goff, S.B.; Kaczala, C.M.; Meece, J.L.; Spence, J.T. Achievement and achievement motivation. Expect. Values Acad. Behav. 1983, 8, 75–146.\n3. Vroom, V.H. Work and Motivation; Wiley: New York, NY, USA, 1964.\n4. Saeed, B.B.; Afsar, B.; Hafeez, S.; Khan, I.; Tahir, M.; Afridi, M.A. Promoting employee’s proenvironmental behavior through green human resource management practices. Corp. Soc. Responsib. Environ. Manag. 2019, 26, 424–438. [CrossRef]\n5. Furby, L. Possessions: Toward a theory of their meaning and function throughout the life cycle. Life Span. Dev. Behav. 1978, 1, 297–336.\n6. Dittmar, H. The Social Psychology of Material Possessions: To Have Is to Be; St. Martin’s Press: New York, NY, USA, 1992.\n7. Belk, R.W. Possessions and the extended self. J. Consum. Res. 1998, 15, 139–168. [CrossRef]\n8. Isaacs, S. Social development in young children. Br. J. Educ. Psychol. 1993, 3, 291–294. [CrossRef]\n9. Kline, L.W.; France, C.J. The psychology of ownership. Pedagog. Semin. 1899, 6, 421–470. [CrossRef]\n10. Pierce, J.L.; Rubenfeld, S.A.; Morgan, S. Employee ownership: A conceptual model of process and effects. Acad. Manag. Rev. 1991, 16, 121–144. [CrossRef]\n11. Beggan, J.K. On the social nature of nonsocial perception: The mere ownership effect. J. Personal. Soc. Psychol. 1992, 62, 229–237. [CrossRef]\n12. Pierce, J.L.; Kostova, T.; Dirks, K.T. Toward a theory of psychological ownership in organizations. Acad. Manag. Rev. 2001, 26, 298–310. [CrossRef]\n13. Pierce, J.L.; Kostova, T.; Dirks, K.T. The state of psychological ownership: Integrating and extending a century of research. Rev. Gen. Psychol. 2003, 7, 84–107. [CrossRef]\n14. Pierce, J.L.; Jussila, I. Psychological Ownership and the Organizational Context: Theory, Research Evidence, and Application; Edward Elgar Publishing: Cheltenham, UK, 2011.\n15. Jussila, I.; Tarkiainen, A.; Sarstedt, M.; Hair, J.F. Individual psychological ownership: Concepts, evidence, and implications for research in marketing. J. Mark. Theory Pract. 2015, 23, 121–139.\n16. Chiu, W.C.K.; Hui, C.H.; Lai, G.W. Psychological ownership and organizational optimism amid China’s corporate transformation: Effects of an employee ownership scheme and a management-dominated board. Int. J. Hum. Resour. Manag. 2007, 18, 303–320. [CrossRef]\n17. Tsai, W.; Ghoshal, S. Social capital and value creation: The role of intrafirm networks. Acad. Manag. J. 1998, 41, 464–476.\n18. Colakoglu, S. Shared vision in MNE subsidiaries: The role of formal, personal, and social control in its development and its impact on subsidiary learning. Thunderbird Int. Bus. Rev. 2012, 54, 639–652. [CrossRef]\n19. Nahapiet, J.; Ghoshal, S. Social capital, intellectual capital, and the organizational advantage. Acad. Manag. Rev. 1998, 23,"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 153, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194876, Requested 7301. Please try again in 653ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194876, Requested 7301. Please try again in 653ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "# Corporate Sustainability in Bangladeshi Banks: Proactive or Reactive Ethical Behavior?\n\nOlaf Weber * and Rezaul Karim Chowdury\n\nSchool of Environment, Enterprise and Development, University of Waterloo, Waterloo, ON N2L 3G1, Canada; reza.cowdury@uwaterloo.ca\n\n* Correspondence: oweber@uwaterloo.ca; Tel.: +1-519-4044-632\n\nReceived: 9 September 2020; Accepted: 25 September 2020; Published: 27 September 2020\n\n# Abstract\n\nThe purpose of this study is to analyze the connection between the sustainability performance and financial performance of Bangladeshi banks to explore the impact of the Bangladesh Environmental Risk Management Guideline. We analyzed all 56 scheduled commercial banks that are currently operating in Bangladesh under the guidelines of the Central Bank of Bangladesh. Data for the sample has been collected from publicly available reports such as annual, sustainability, and corporate social responsibility (CSR) reports, disclosed sustainability and financial information on the banks’ websites, including all bank branches, and data published from the Central Bank. Data has been analyzed using panel regression. Our results indicate that higher sustainability performance creates a higher financial performance, and that bigger banks perform better with regard to sustainability than smaller banks. The analysis did not find, however, that higher financial performance influences the sustainability performance of the banks positively. Consequently, this research contributes to the research on legitimacy-driven behavior of Bangladeshi banks. This behavior rather leads to a reactive adoption of sustainability activities instead of proactive behavior.\n\n# Keywords\n\nsustainable banking; Bangladesh; legitimacy\n\n# 1. Introduction\n\nRecently, there has been an increasing number of calls for a more sustainable financial industry [1] that even motivated the Financial Stability Board of the G20 to establish a Task Force on Climate-Related Disclosure [2]. With the economic rise of many Asian countries, integrating sustainable finance into the financial industry of these countries is important to address environmental and social issues, such as environmental pollution [3] and inequality [4]. To address both organizational ethics and financial sector stability, several countries, among them China and Bangladesh, introduced financial industry sustainability policies in addition to voluntary codes of conduct implemented by the industry. These countries experience severe environmental issues, such as air and water pollution, that have significant effects on their population and therefore try to decrease lending to and investing in polluting industries as well as to increase financing of more environmentally friendly industries. Bangladesh Bank, for instance, introduced the Environmental Risk Management Guidelines (ERM) in 2011 [5] to engage the financial sector in green finance.\n\nAs financial sector sustainability regulations are relatively new, there is a lack of research about the effect of these policies on both the financial and the sustainability performance of the regulated industries. Furthermore, there is a gap in the knowledge about the connection between sustainability performance and the financial performance of banks in countries with such policies. Most of the studies published so far address the Chinese Green Credit Policy [6–10]. Those studies found a positive effect of green banking activities, such as green lending and the financial performance of the financial.\n\nSustainability 2020, 12, 7999; doi:10.3390/su12197999 www.mdpi.com/journal/sustainability\n\n# Sustainability 2020, 12, 7999\n\ninstitutions. Studies addressing a South Asian country such as Bangladesh are sparse, and their results are controversial. However, they agree that sustainable banking, including corporate social responsibility (CSR) reporting, is in an early phase in Bangladesh [11–15].\n\nThough ERM has been introduced in 2011, only a few banks in Bangladesh even adopted green banking guidelines at this time [16]. However, Ahmed and Ahmed [17], for instance, found that the sustainability performance of Bangladeshi banks has increased since then. Nevertheless, they did not find a correlation between their environmental and financial performance. Other studies that addressed the lending business, however, found that integrating sustainability criteria into the lending business decreases the number of default loans and consequently has a positive impact on a lender’s financial performance [18]. Despite some research on sustainability in Bangladeshi banks, the question remains whether regulatory sustainability guidelines improve both the environmental and financial performance of the regulated banks.\n\nWe use legitimacy theory [19, 20] to explain why and how Bangladeshi banks adopt sustainability strategies and what the consequences are for their financial performance. The theory states that banks will adopt environmental regulations and increase their sustainability performance if there is outside pressure. Furthermore, the theory claims that external pressure is stronger for bigger banks than smaller banks. Finally, according to the theory, adopting guidelines because of legitimacy concerns will not lead to integration into the banks’ strategies. Consequently, our three research questions are whether higher sustainability performance increases financial performance, whether better financial performance leads to higher sustainability performance, and whether bigger banks perform better with regard to sustainability than smaller banks.\n\nTo respond to the research questions, we analyzed all 56 regulated Bangladeshi banks between 2012 and 2016 based on their annual reports, CSR, or similar reports and on the information from their websites. In line with a study that addressed a similar question in China [8], an indicator system that consists of social and environmental sustainability indicators has been used to calculate a sustainability score (SS) for the banks. The score has been used as the independent variable to predict the financial performance of the banks as well as the dependent variable based on a lagged panel regression and Granger causality calculation [21].\n\nThe results of the study demonstrate that higher sustainability performance creates higher financial performance. However, the analysis did not find that higher financial performance influences the sustainability performance of the banks positively. Finally, we could show that bigger banks perform better with regard to sustainability than smaller banks.\n\nFollowing legitimacy theory, we conclude that the analyzed banks are rather reactive"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197948, Requested 7971. Please try again in 1.775s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197948, Requested 7971. Please try again in 1.775s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "corporate sustainability has become more commonly accepted in China, there has been no agreed-upon definition of it. Therefore, the standardisation and the regulations of corporate sustainability in China are in a great need of development (Bai et al., 2015).\n\n# 2.2 Global Reporting Initiative (GRI) guidelines in China\n\nIn China, the GRI (2013) guidelines are used as the basis of most sustainability reportings. In recent decades, GRI has attempted to provide comprehensive guidelines for CSD by setting indicators in corporate economic, environmental and social sustainability (Chauvey et al., 2015). Firms that adopt GRI Sustainability Reporting Guidelines need to report their strategy in the company profiles, explain their management approach as to how they address corporate sustainability practices and disclose their company sustainability (economic, environmental and social) performance (Hahn and Lulfs, 2013). GRI, overall, provides companies with information on how and what to report in CSD.\n\nWhile GRI provides such comprehensive sets of guidelines on CSR, it ultimately aims to enhance companies’ information transparency and overall accountability. This has elevated the GRI Sustainability Reporting Guidelines to become the most commonly used framework internationally (Hahn and Lulfs, 2013). The KPMG Questionnaire into CSR (KPMG, 2008) examined the top 250 companies listed on the Fortune Global 500 and the 100 largest firms by revenue in 22 countries. The results showed that more than 75 per cent of companies from the Fortune Global 500 and 70 per cent of the 100 largest revenue firms applied the GRI. GRI is also considered practical for firms to use as report preparers are able to self-examine their own level of corporate sustainability performance.\n\nAs suggested by Brown et al. (2009), GRI is significant in terms of its “broad range of stakeholders” approach, as well as institutionalising multi-stakeholders on reporting and accountability. However, Drori et al. (2006) indicated that GRI is mostly presented by multinational companies on a global basis and international accounting firms have large influence on standardising the guidelines. Western multinational firms, therefore, help to set the agenda on corporate sustainability reporting based on their own interests (Vigneau et al., 2015). It is suggested that “the guidelines’ lack of universal applicability creates a perceived unfairness inherent in imposing Western standards of social behaviour and associated reporting practices” (Adams and McNicholas, 2007, p. 484).\n\nNevertheless, GRI remains highly authoritative globally because of its context, language, concepts and assumptions (Brown et al., 2009). It has a significant role to highlight the importance of corporate sustainability reporting and has led to new practices of corporate sustainability and responsibility (Vigneau et al., 2015). Hopkins (2004) also contends that the GRI guidelines include some aspects of the other popular environmental and social guidelines, such as the ISO 14000 and the global Sullivan principles.\n\n# 2.3 Perceptions and motivations of sustainability in China\n\nEarly studies on the topic of perception of CSR in the Chinese context have broadly discussed the differential impact to measure CSR based on the Western and the Chinese definitions. Both Western and Chinese literature indicates that corporate sustainability is, to some degree, directly related to shareholders and companies values, as well as the need for the companies to be legitimate and ethical. Cultural differences have also created some different perceptions about corporate sustainability in the West and the East. Many studies, which were conducted in China, into Chinese culture and corporate sustainability, have explored the idea of profits from righteousness (Yi) principle, derived from Confucius.\n\nAnother stream of studies on CSR perception in China is generally focused on the potential of political interference and government intervention, and it examines the disclosure content to reveal the propensity for firms to report on government policies (Gao, 2011; Kuo et al., 2012; Li and Zhang, 2010; Marquis and Qian, 2014). Kuo et al. (2012), based on a content analysis of Chinese data obtained from CSR reports, found that environmental sensitivity and ownership structures distinguish corporate environmental disclosures. Sensitive industries and government-owned firms are found to be more committed to providing environmental disclosures than less-sensitive industries and non-government-owned firms. They were also highly engaged in energy saving, carbon reduction, research and application of new techniques – beneficial activities that assist China in dealing with the global warming issue. Kuo et al.’s (2012) study also suggested that the Chinese government has an important role in promoting corporate CSR engagement.\n\nMarquis and Qian (2014) examined corporate strategic response to government signals through CSR disclosure. They examined 1,600 listed firms between 2006 and 2009, and their results supported the findings of Kuo et al. (2012) that the Chinese government’s signalling is a critical driver for corporate reporting, particularly for the SOEs that exert substantial political influence. Further, they found that the reporting companies are highly subjective to decoupling risk under specific monitoring mechanism. The expectation of policymakers drove the reported CSR practices.\n\nGao (2011) found that the listed companies in the Chinese financial market had, overall, a positive attitude to engage in CSR. Specifically, they found that SOEs have a higher tendency to engage in social issues through CSR than the non-SOEs. Gao (2011) suggested that political promotion on the ideology of CSR has important meanings for SOEs’ CSR engagement. Further, industrial firms were also found to have higher propensities on CSR than service industries.\n\nThrough a discussion of the interplay of the global and national societal pressures in China, Hofman et al. (2017) suggested that CSR practices by Chinese firms are highly “state-led” and “local-driven”. They"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 195502, Requested 8172. Please try again in 1.102s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 195502, Requested 8172. Please try again in 1.102s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "# Corporate sustainability disclosure’s importance in China: financial analysts’ perception\n\n# Jhunru Zhang, Hadrian Geri Djajadikerta and Terri Trireksani\n\n# Abstract\n\nPurpose – Corporate sustainability in China has become a subject of increasing international concern. Corporate sustainability disclosure (CSD) is considered a useful tool to facilitate the empowerment and acknowledgement of stakeholders in the quest for sustainability. However, the degree of cultural and political influences for being sustainably orientated can be significantly different between countries. This study aims to examine the perception of financial analysts, as CSD report users, in China about the level of importance of various indicators of corporate sustainability described in the Global Reporting Initiative (GRI) Sustainability Reporting Guidelines.\n\nDesign/methodology/approach – A set of questionnaires was developed based on GRI G4 guidelines to measure the perception of financial analysts in China on the level of importance of each sustainability indicator described in the GRI G4. A five-point Likert scale was used to measure the report users’ perceptions of each of the indicators.\n\nFindings – The findings of this study increase our understanding of how Chinese CSD report users perceive corporate sustainability differently from the GRI guidelines. The main results show that the environmental aspect of sustainability was seen to be important in China, followed by the social and economic aspects. Indicator-wise, “water”, “effluents and waste”, “emissions”, “compliance” and “energy” were perceived as vital in the environmental category, while “customer health and safety”, “customer privacy” and “compliance” were considered significant in the social category.\n\nOriginality/value – This study addresses the need for differing corporate sustainability guidelines for different nations and cultures, specifically within the Chinese context. It also contributes to the corporate sustainability literature by adding to our understanding of how financial analysts in China, as CSD report users, perceive aspects of sustainability.\n\nKeywords China, Financial analysts, Sustainability, GRI, Corporate sustainability disclosure, Users’ perception\n\nPaper type Research paper\n\nJhunru Zhang and Hadrian Geri Djajadikerta are both based at the School of Business and Law, Edith Cowan University, Joondalup, Australia. Terri Trireksani is based at the School of Business, Murdoch University, Perth, Australia.\n\n# 1. Introduction\n\nWhile the economic development of China over the preceding decades has led to significant improvement in its national prosperity, it has also generated a considerable degree of concern about corporate sustainability. Corporate sustainability disclosures (CSD) are generally considered to be the most effective and efficient way for companies to facilitate the empowerment and acknowledgement of company stakeholders’ quest for sustainability and to inform the society about their sustainability performance (Qian et al., 2015). Because of the lack of comprehensive and effectively enforced CSD regulations, the growth of corporate sustainability practices in China extensively depends on voluntary disclosure practice (Zhang et al., 2015).\n\nHowever, as Received 21 October 2018 Revised 8 July 2019 Accepted 14 July 2019 DOI 10.1108/SRJ-10-2018-0272 © Emerald Publishing Limited, ISSN 1747-1117 jSOCIAL RESPONSIBILITY JOURNAL j\n\nRecognised the importance of issuing corporate sustainability reports because of the severe environmental deterioration and significant social issues raised in tandem with the boost of the Chinese economy.\n\nFor example, the serious milk powder corporate scandals in mainland China have raised extreme concern regarding companies’ social responsibility: in 2008, Sanlu Group added melamine into the formula of milk powder to boost the protein content. Infants who consumed this product were highly likely to develop kidney stones or even an illness that was fatal if seriously affected. Sanlu Group was one of the largest milk powder manufacturers and sellers in China for over 15 continuous years, and it was once the biggest taxpayer. The revelation of the scandal caused the failure and bankruptcy of Sanlu, and, more importantly, it destroyed people’s confidence in the Chinese milk powder supply industry. The 300,000 victims triggered considerable social pressure, which consequently affected thousands of workers, causing them to lose their jobs (Nornha et al., 2013). Society, as a result, had to bear this significant social cost.\n\nAs such, the unique context in China provides a significant setting to examine CSD perception from its users’ end. The local Chinese community, in general, has relatively high societal acceptance towards CSD information. Under the Confucius perspective, maximising shareholders’ value and financial profit should not be the only goal of making corporations sustainable (Liu and Anbumozhi, 2009). Xia et al. (2009) emphasised the idea of righteousness before profits and stated that the fundamental value of ethics should reflect the business values. Hence, concerns and actions should always be closely related to all of the customers’, employees’ and shareholders’ values, and sustainability information is in favour for the general community as Confucian culture has been embedded in the basis of modern corporate sustainability in Chinese companies (Zhu and Yao, 2008).\n\nIn addition, Chinese enterprises are increasingly pressured by numerous stakeholders and by the general public to engage in social and environmental sustainability. In particular, in China, the Shenzhen Stock Exchange (SZSE) and Shanghai Stock Exchange (SSE) have made a great effort to promote corporate governance initiatives in past years. Ho (2013) indicates that the rapid growth of these markets is significantly influenced by two essential pieces of legislation: the Company Law and the Securities Law, enacted in 1993 and 1998, respectively. The Company Law provides the legal requirement for the transformation of state-owned enterprises (SOEs) into private or listed enterprises. To conform to the two legislations, the stock exchanges in China have implemented guidelines for their listed corporations to take responsibility for their stakeholders. The SZSE issued the Corporate Social"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194590, Requested 7487. Please try again in 623ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194590, Requested 7487. Please try again in 623ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "Plan (Zhang et al., 2018). Our target respondents were the financial analysts who worked at securities organisations that were registered on the China Securities Regulatory Commission (www.csrc.gov.cn). To approach the financial analysts as our study’s respondents, we sent an email to 200 financial managers who worked at these registered security companies. Their contact information was obtained online. Each manager was also asked to distribute our Web-based survey URL to their financial analysts. We received 129 usable responses. Table I shows the demographic information of the respondents of the survey.\n\n# 3.3 Data analysis\n\nIn this study, we build on and extend the work of Chow and Chen (2012). Chow and Chen (2012) have indicated the validity of the scale by GRI from the report preparers’ end. We did a validity test by applying the EFA to explore the perceived importance of corporate sustainability reporting from the report users’ perceptive. EFA is commonly used for interpreting self-reporting questionnaires which have been widely used in existing perception and motivation-based CSR research (Dincer and Dincer, 2012; Firmialy and Nainggolan, 2018; Hayton et al., 2004; Latif et al., 2018; Sheng and Chen, 2010). We performed EFA because it reduces a large number of reflective and latent measures into a smaller set (Hair et al., 1995); hence, it confirms the dimensions defined by the GRI and fosters our hypotheses testing in the later part of the study. EFA also provides the significance of validity for the construct under the GRI based on our questionnaires (Hayton et al., 2004).\n\nTo test our hypotheses, we adopted t-tests to confirm the level of importance based on our questionnaire results. t-tests are commonly used to determine if there is any significant difference between two sets of scores. A one-sample t-test is often considered when only a single sample of the participants and the questions are used to determine whether the\n\n# Table I Respondents’ profiles (N = 129)\n\n|Demographic variables|Frequency|(%)|\n|---|---|---|\n|Gender| | |\n|Male|61|47.3|\n|Female|68|52.7|\n|Location| | |\n|Beijing|55|42.6|\n|Shenzhen|31|24|\n|Jilin|43|33.3|\n|Education| | |\n|Below undergraduate level|4|3.1|\n|Undergraduate degree|67|51.9|\n|Postgraduate degree|55|42.6|\n|PhD|3|2.3|\n|Years of experience| | |\n|Less than 2 years|45|34.9|\n|3-4 years|14|10.9|\n|5-6 years|40|31|\n|7-8 years|16|12.4|\n|9 years and more|14|10.9|\n\nThe mean of the population from which the sample is drawn is the same as the hypothesised mean (Hair et al., 1995). In this study, one-sample t-test was adopted because the mean value drawn from the users’ perceived importance of each type of sustainability disclosure was compared with the level of importance intended by GRI (i.e. the value of 4 as per the Likert scale used).\n\n# 4. Results and analysis\n\n# 4.1 Exploratory factor analysis\n\nBased on the definition of the sustainability items from GRI, we prepared reflective indicators in the questionnaires in terms of environmental indicators, economic indicators, social indicators – labour and decent work, social indicators – human rights, social indicators – society and social indicators – product responsibility. The estimation of the EFA results is presented in Table II. Unsurprisingly, EFA reveals six underlying dimensions, which are consistent with the sustainability definition by GRI. We follow the similar approach of Latif et al. (2018) in the critical assumption of EFA. Firstly, our correlation matrix shows that all items were significant at p < 0.001 level. Interestingly, we detect that “environment grievance” in the environmental indicator construct has a relatively low factor loading of 0.134. One explanation is that there were limited ways of environmental grievance in the Chinese context because of the lack of government monitoring controls over corporate environmental performance (Chen et al., 2017). Additionally, our result also suggests the suitability of factors with Bartlett’s test of sphericity (x² = 3698.805, df = 946 and p < 0.01) that measures the probability of the correlation matrix with other components, where the Kaiser–Meyer–Olkin (KMO) measure is 0.849 at 0.01 significance level. Lastly, we accounted for 51.885 per cent of the variation in our data based on the six factors yielded from the scales based on EFA. We further performed a reliability test, in which our Cronbach’s alphas are substantially above the critical value of 0.7. Based on the results from EFA, our results overall show sufficient convergent validity in each construct, which allows us to perform the following t-tests for hypothesis testing.\n\n|Items|Indicators|Indicators|Indicators| | |\n|---|---|---|---|\n|Environmental indicators|Economic indicators|Social indicators (labour and decent work)| |\n|1. Water|0.545| | |\n|2. Effluents and waste|0.696| | |\n|3. Emissions|0.805| | |\n|4. Compliance|0.570| | |\n|5. Energy|0.557| | |\n|6. Supplier environmental assessment|0.543| | |"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194471, Requested 8156. Please try again in 788ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194471, Requested 8156. Please try again in 788ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "as the independent variable to predict the financial performance of the banks as well as the dependent variable based on a lagged panel regression and Granger causality calculation [21].\n\nThe results of the study demonstrate that higher sustainability performance creates higher financial performance. However, the analysis did not find that higher financial performance influences the sustainability performance of the banks positively. Finally, we could show that bigger banks perform better with regard to sustainability than smaller banks.\n\nFollowing legitimacy theory, we conclude that the analyzed banks are rather reactive concerning their sustainability strategy and that they mainly respond to the institutional pressure of Bangladesh Bank because of legitimacy purposes. Instead of integrating sustainability aspects into their core business to decrease risks and to increase the opportunities of green banking, and consequently increase their financial performance, banks rather react in a stakeholder-oriented fashion to keep their legitimacy. Consistent with legitimacy theory, they are biased towards activities favorable to stakeholders instead of a strategic sustainability approach.\n\nThe study contributes to legitimacy theory in sustainable banking and its financial consequences. It demonstrates that increased sustainability performance has a positive effect on the financial performance of banks, as intended by Bangladesh Bank’s ERM, but that this information is not integrated into the banks’ business strategies. Furthermore, the research contributes to legitimacy theory by adding knowledge about the legitimacy-driven behavior of South Asian banks. Moreover, our results contribute to theory by suggesting that legitimacy-driven behavior might not lead to strategic corporate sustainability that addresses the main societal issues in a proactive way.\n\nThe remainder of the paper describes the background literature and the theory, followed by the presentation of the sample and methods. Finally, we report the results of the study and finish with a discussion and conclusions.\n\n# 2. Background\n\nSeveral studies have analyzed financial sustainability regulations and their impact on regulated banks. Most of these studies explore the impact of the Chinese Green Credit Guidelines. Some studies, however, also examine Bangladeshi banks with regard to their sustainability. In general, however, studies on this topic in South Asia are sparse. The following sections present an overview of empirical findings on banks and sustainability, financial sector sustainability regulations and policies, as well as theoretical findings on financial sector sustainability regulations and sustainability in banking.\n\nBanks started integrating non-financial environmental and social aspects into their business during the 1980s. Firstly, they addressed internal environmental management [22], resulting in water, energy, and materials savings, as well as in lower emissions and high reputation [23]. As the second step, banks integrated environmental issues into lending, investing, asset management, and project finance [24]. Hence, they became CSR intermediaries [25] that influence the CSR of their clients, because higher corporate social performance (CSP) mitigates borrowers’ financial risks [26]. Consequently, voluntary sustainability codes of conduct, such as the United Nations Environmental Program Financial Initiative (UNEPFI), the UN Principles for Responsible Investing (UNPRI), and the Equator Principles have been instigated [27].\n\nSustainability risks, such as those caused by climate change or negative environmental impacts of commercial borrowers or investees, have a significant influence on the financial risk of credit and investment portfolios. Consequently, they have to be managed thoroughly [7, 28]. Therefore, many banks have implemented sustainable credit risk assessment procedures [29] and have been using environmental, social, and governance criteria to conduct responsible investments [30 – 32]. Some studies, however, suggest that the sustainability strategies of many banks are not substantially addressing their core business and the main societal issues [33].\n\nFor a long time, the pressure on the financial sector to perform well concerning the sustainability impact of their main products and services, such as lending and investing, has been lower than in many other industries (Weber et al., 2014). Studies have found, however, that environmental and sustainability reporting positively correlates with the size and the profitability of financial institutions [14, 34, 35]. Furthermore, the integration of environmental and sustainability issues into financial sector products and services has been increasing over time and has positive effects on the banks’ financial performance (Scholtens, 2008a).\n\nConsequently, one of the motivations for integrating sustainability into the banking business is the correlation with the financial performance of banks. Igbudu and Garanti [36] suggest that sustainable banking increases the banks’ loyalty and corporate reputation, while a study in Germany identified a strong growth potential for social banking [37] and, therefore, a new market to tap into. Furthermore, studies found a positive connection between corporate social responsibility and financial performance in the banking sector [38, 39], between sustainability, measured by the membership in the Dow Jones Sustainability Index (DJSI), and efficiency [40], as well as between responsible investing and financial returns [41, 42]. However, Climent [43] found that ethical banks are less profitable than their conventional counterparts but that they have more substantial growth in their lending business.\n\nAdditionally, several studies suggest that banks are rather reactive and defensive concerning the incorporation of sustainability aspects into their core businesses [44, 45]. Many of them focus on short-term results and do not integrate sustainability into their core business [46]. The need for a sustainability culture [47] to develop capabilities and to provide resources to improve corporate sustainability performance, however, is not only a phenomenon in the financial industry but in all sectors [48 – 51]. Consequently, financial sector sustainability regulations should take into account that banks might not have the necessary capabilities and resources to implement the regulations efficiently in a way that increases their financial performance.\n\nThough heavily regulated compared with other industrial sectors, the financial sector’s exposure to institutional pressure and regulations addressing sustainability [52], environmental, and societal risks [53, 54] is relatively small. Financial sector regulations focus mainly on risk-adjusted.\n\n# Sustainability 2020, 12, 7999\n\nfinancial capital provisions, financial risks, and guaranteeing the stability of the financial industry. Newer approaches, however, also address the"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 153, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197130, Requested 7206. Please try again in 1.3s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197130, Requested 7206. Please try again in 1.3s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "contrast, a heterogeneous identity (Gioia, Schultz, & Corley, 2000; Pratt & Foreman, 2000) admits more diverse aspects and, thus, makes ambivalent evaluations more likely (Plambeck & Weber, 2010). Organizations with heterogeneous conceptualizations of their central, distinctive, and enduring features accommodate multiple interpretations (Gioia et al., 2000) and tend to have more complex relationships with a wide spectrum of external stakeholders (Brickson, 2005). In such organizations decision makers are more likely to integrate conflicting sustainability aspects in their issue evaluations, because their organization’s identity allows for attending to a wide variety of competing stakeholder demands (Hamilton & Gioia, 2009).\n\n# Proposition 5a:\n\nDecision makers in organizations with a homogeneous business identity are less likely to interpret sustainability issues ambivalently, which will weaken the effects of the paradoxical frame on interpretation.\n\n# Proposition 5b:\n\nDecision makers in organizations with a heterogeneous identity are more likely to interpret sustainability issues ambivalently, which will weaken the effects of the business case frame on interpretation.\n\nGiven the role of resource availability as an important contextual factor in strategic issue diagnosis (Dutton & Duncan, 1987), we expect resource constraints to also moderate the influence of cognitive frames on the interpretation of sustainability issues. Resource constraints influence both managerial sense of control and issue valence. In cases where “resources are abundant, decision makers are more likely to feel a sense of control . . . with respect to an issue, than when organizational resources are limited” (Denison, Dutton, Kahn, & Hart, 1996: 459), because they have the means available to deal with the issue adequately (Jackson & Dutton, 1988). In contrast, with limited resources, decision makers feel constrained by their context in the choices they can make and, thus, experience a loss of control (George et al., 2006; Jackson & Dutton, 1988). A lack of resources also makes ambivalent interpretations of strategic issues less likely, since managers tend to lack the time and resources to investi-\n\n476 Academy of Management Review October\n\ngate a greater diversity of aspects of the issue (Plambeck & Weber, 2010).\n\nWe expect that resource constraints will particularly influence the interpretation of sustainability issues under a paradoxical frame. Having only a moderate sense of control to start with, decision makers’ sense of control will be further reduced by resource constraints, since these individuals lack time and resources to process the broad range of aspects they perceive. In addition, in times of economic distress, financial aspects are more likely to come to the fore owing to increased shareholder pressure. This will reduce managers’ leeway to consider a wider range of environmental and social aspects that potentially conflict with financial performance. Managers will therefore be forced to take sides and interpret sustainability issues less ambivalently. However, they will feel that this more univalent interpretation is imposed on them rather than being the result of their own reasoning, which will further reduce their sense of control. In contrast, when managers with a business case frame operate under resource constraints, they will still seek univalent interpretations. Resource constraints tend to reinforce their reliance on routine procedures to ascertain the business relevance of sustainability issues in order to maintain control (George et al., 2006). Hence, resource constraints will affect such managers to a lesser degree. They will continue to settle univalently for either positive or negative evaluations, even with a low sense of control (Plambeck & Weber, 2009, 2010). We therefore suggest the following relationship between resource availability and managerial interpretation of sustainability issues (see the dotted curve in Figure 3).\n\n# Proposition 6:\n\nA lack of time and resources will induce decision makers with a paradoxical frame to perceive a lower sense of control over sustainability issues and to interpret sustainability issues more univalently but will not affect the interpretation of decision makers with a business case frame.\n\n# Responding\n\nOnce managers have interpreted ambiguous sustainability issues based on their cognitive frame, they will act on that basis. While the cognition of an individual decision maker alone will not determine organizational responses to sustainability issues, we expect that different cognitive frames will lead managers to adopt different decision-making stances. We define stance as a decision maker’s rationalized mental attitude toward an issue, which predisposes the individual to act in certain ways. We argue that the different effects we expect for the two frames with regard to depth and breadth of scanning (Mazutis, 2013) and issue interpretation in terms of sense of control and issue valence (Chattopadhyay et al., 2001; Plambeck & Weber, 2009) will result in different decision-making stances on sustainability issues—that is, either a pragmatic stance or prudent stance. We further characterize these two stances by discussing the scope, novelty, swiftness, and riskiness (Plambeck & Weber, 2009) these different types of responses entail.\n\nAs developed above, managers with a business case frame focus in detail on selected aspects of sustainability issues to understand their relevance for economic objectives. Based on focused search routines, they develop a high sense of control over the few sustainability issues they perceive and tend to evaluate these issues univalently as either clearly positive or negative for their business. Consequently, we expect these managers to consider responses that either actively approach an issue—in the case of a positive evaluation—or actively avoid it—in the case of a negative evaluation (Cacioppo, Gardner, & Berntson, 1999). To develop these responses, they refer to existing solutions that have been successfully applied to similarly interpreted issues (Ocasio, 1997): they “access common solutions when faced with common situations that are clearly positive or negative” (Plambeck & Weber, 2009: 998). Being based on"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 153, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 196004, Requested 7035. Please try again in 911ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 196004, Requested 7035. Please try again in 911ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "to the origin of cognitive frames. Since managers’ frames “do not spring up randomly, but rather are the encoding of their prior history” (Kaplan & Tripsas, 2008: 791), we would expect that a range of factors at personal, organizational, and institutional levels will influence the formation of cognitive content and structure. With regard to personal background, researchers have argued that personality traits, such as need for closure (Webster & Kruglanski, 1994) and tolerance for ambiguity (Furnham & Ribchester, 1995), play an important role in sensemaking under conditions of uncertainty and ambiguity (McKenzie, Woolf, van Winkelen, & Morgan, 2009). With regard to the organization as a context for managerial decision making (Gioia & Thomas, 1996; Weick, 1979), the influence of organizational structure on managers’ cognition (Hannaway, 1985) may differ between centralized and decentralized organizations (Pugh et al., 1963). Moreover, since managers’ cognitive frames are shaped by the particular institutional fields they have been exposed to (Weber & Glynn, 2006), dominant and contested institutional logics (Purdy & Gray, 2009; Reay & Hinings, 2009) may prime different cues and privilege certain frames over others (Weber & Glynn, 2006). Future research into the antecedents of the business case frame and the paradoxical frame will help us to understand who the managers are that are more likely to adopt a pragmatic or a prudent stance on sustainability issues.\n\nOur focus on cognition at the individual level raises the question of how different cognitive frames and the resulting decision-making.\n\nstances relate to organizational action (Dutton & Jackson, 1987; Thomas et al., 1993). We see at least two key aspects at the interface between individual cognition and organizational action that merit further investigation: the activation of frames and the dominance of frames. A better understanding of the factors that trigger a stronger or weaker activation of the two frames promises relevant insights. Such factors may be found within the organization—for instance, in an organizational climate of participation (Tesluk, Vance, & Mathieu, 1999) and creativity (Ekvall, 1996)— or outside the organization—in major regulative, technological, or economic discontinuities (Griffith, 1999; Tushman, Newman, & Romanelli, 1986). Moreover, since managerial cognition is a social process within an organizational context (Daft & Weick, 1984), individual frames will only translate into organizational action when they are transformed “into the organization’s predominant collective frames” (Kaplan, 2008: 730). Collective cognitive frames are the outcome of a political process where organizational members compete over the dominant interpretation of an issue (Gioia & Chittipeddi, 1991). Future research could address the factors that enable decision makers to translate their own cognitive frame into the dominant collective frame. Overall, further development of the cognitive framing perspective may result in a more comprehensive theory that establishes a connection among individual history, cognition, and agency.\n\nWe believe that our cognitive framing perspective and our propositions provide ample opportunities for future empirical studies. Given the nascent state of research into tensions and cognitive diversity in sustainability, scholars may find it most fruitful to use both quantitative and qualitative methods (Edmondson & McManus, 2007). However, testing our propositions through quantitative research presupposes the development of measurement scales for the business case frame and the paradoxical frame. To gain insights into the cognitive processes of decision makers who use business case frames or paradoxical frames, (semi-)qualitative methods, such as interviews, content analyses, and exploratory case studies, will be particularly suitable (Grégoire, Barr, & Shepherd, 2010; Lüscher & Lewis, 2008).\n\nIn conclusion, we believe that a cognitive framing perspective offers a better understanding of managerial decision making on sustainability issues by recognizing the importance of a greater cognitive diversity of managers with regard to the content and structure of their frames. Our goal in this research, therefore, has not been to advocate a specific cognitive frame but, rather, to pave the way for the consideration of different cognitive perspectives on complex and ambiguous issues, such as corporate sustainability.\n\n# REFERENCES\n\nAlbert, S., & Whetten, D. A. 1985. Organizational identity. Research in Organizational Behavior, 7: 263–295.\n\nAndersson, L. M., & Bateman, T. S. 2000. Individual environmental initiative: Championing natural environmental issues in U.S. business organizations. Academy of Management Journal, 43: 548 –570.\n\nAngus-Leppan, T., Benn, S., & Young, L. 2010. A sensemaking approach to trade-offs and synergies between human and ecological elements of corporate sustainability. Business Strategy and the Environment, 19: 230 –244.\n\nBansal, P. 2002. The corporate challenges of sustainable development. Academy of Management Executive, 16(2): 122–131.\n\nBansal, P. 2005. Evolving sustainably: A longitudinal study of corporate sustainable development. Strategic Management Journal, 26: 197–218.\n\nBansal, P., & Roth, K. 2000. Why companies go green: A model of ecological responsiveness. Academy of Management Journal, 13: 717–736.\n\nBarr, P. S., & Huff, A. S. 1997. Seeing isn’t believing: Understanding diversity in the timing of strategic response. Journal of Management Studies, 34: 337–370.\n\nBarr, P. S., Stimpert, J"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194156, Requested 8172. Please try again in 698ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194156, Requested 8172. Please try again in 698ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "|Private Commercial Banks (PCB)|\n|NRB Global Bank Limited|Private Commercial Banks (PCB)|\n|One Bank Limited|Private Commercial Banks (PCB)|\n|Premier Bank Limited|Private Commercial Banks (PCB)|\n|Prime Bank Ltd|Private Commercial Banks (PCB)|\n|Pubali Bank Limited|Private Commercial Banks (PCB)|\n|Rajshahi Krishi Unnayan Bank|State-Owned Commercial Banks (SOCB)|\n|Rupali Bank Limited|Private Commercial Banks (PCB)|\n\n# Sustainability 2020, 12, 7999\n\n# Table 1. Cont.\n\n|Bank Name|Type of Bank|\n|---|---|\n|Shahjalal Islami Bank Limited|Islamic Banks (IB)|\n|Social Islami Bank Ltd.|Islamic Banks (IB)|\n|Sonali Bank Limited|State-Owned Commercial Banks (SOCB)|\n|South Bangla Agriculture & Com. Bank Limited|Private Commercial Banks (PCB)|\n|Southeast Bank Limited|Private Commercial Banks (PCB)|\n|Standard Bank Limited|Private Commercial Banks (PCB)|\n|Standard Chartered Bank|Foreign Commercial Banks (FCB)|\n|State Bank of India|Foreign Commercial Banks (FCB)|\n|The City Bank Ltd.|Private Commercial Banks (PCB)|\n|The Farmers Bank Ltd|Private Commercial Banks (PCB)|\n|The Hong Kong and Shanghai Banking Corp. Ltd.|Foreign Commercial Banks (FCB)|\n|Trust Bank Limited|Private Commercial Banks (PCB)|\n|Union Bank Limited|Private Commercial Banks (PCB)|\n|United Commercial Bank Limited|Private Commercial Banks (PCB)|\n|Uttara Bank Limited|Private Commercial Banks (PCB)|\n|Woori Bank|Foreign Commercial Banks (FCB)|\n\nFinancial data was gathered from the banks’ annual reports. We used total assets (TA), net profit after tax (NPAT), return on assets (ROA), and return on equity (ROE) as key financial accounting indicators. In line with [19], TA was used to measure the size of the banks. The other indicators have been used by similar studies that address the link between sustainability performance and financial performance in the banking sector (see, for instance, [7,8,38,77]).\n\nThe analysis of the sustainability performance was conducted in line with earlier studies that analyzed the sustainability performance of banks [8]. It is based on the framework of the Global Reporting Initiative [74]. The analysis assessed the presence of strategies, activities, products, and services in the categories of social sustainability, environmental sustainability, and green products and services. The latter were assessed because they are addressed by the ERM. If an indicator was mentioned, a bank achieved a value 1 for the indicator. Otherwise, it achieved the value 0.\n\nTo analyze Granger causality [21], we used panel regression models with one-year lags for sustainability performance and financial performance, respectively. As the Hausman test [78] was significant, we used fixed-effects models. To control for accuracy of the regression, we used bootstrapping [79].\n\n# 5. Results\n\nWe start by presenting the major financial and sustainability indicators of the banks in the sample, split by banking types (see Table 2). In line with Bangladesh Bank, we distinguished between conventional commercial banks, foreign commercial banks, Islamic banks, specialized banks, and state-owned commercial banks.\n\n# Sustainability 2020, 12, 7999\n\n# Table 2. Financial and sustainability indicators split by bank type.\n\n|Bank Type|Total Assets|Net Profits|ROA|ROE|NPL Ratio|Social|Env.|Green|Sustainability| |\n|---|---|---|---|---|---|---|---|---|---|---|\n|Conventional commercial|Average|135,871.40|1413.37|0.98%|9.70%|5.81%|0.43|0.58|0.29|0.43|\n| |Std. Dev.|92,390.02|1211.72|0.66%|5.45%|15.15%|0.21|0.29|0.18|0.21|\n|Foreign commercial|Average|79,485.69|1726.81|1.37%|8.24%|5.26%|0.30|0.66|0.12|0.36|\n| |Std. Dev.|77,342.22|2964.60|6.62%|10.13%|4.44%|0.12|0.19|0.12|0.12|\n|Islamic bank|Average|213,850.90|1797.99|0.55%|7.77%|11.65%|0.42|0.61|0.22|0.42|\n| |Std. Dev.|208,579.00|1587.95|1.76%|7.80%|23.23%|0.17|0.25|0.11|0.17|\n|Specialized bank|Average|135,491.60|−4580.30|−2.40%|−6.83%|22.90%|0.37|0.43|0.08|0.29|\n| |Std. Dev.|82,663.93|9151.55|4.19%|8.61%|6.70%|0.03|0.26|0.12|0.12|\n|State owned commercial|Average|307,341.60|−1172.75|"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 153, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 195048, Requested 6683. Please try again in 519ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 195048, Requested 6683. Please try again in 519ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": ". 2013. Douchen is een fijne verslaving [Showering is a fine addiction]. September 28/29: E2–3.\n\nOcasio, W. 1997. Towards an attention-based view of the firm. Strategic Management Journal, 18: 187–206.\n\nO’Leary, B., & Weathington, B. 2006. Beyond the business case for diversity in organizations. Employee Responsibilities and Rights Journal, 18: 283–292.\n\nPache, A.-C., & Santos, F. 2013. Inside the hybrid organization: Selective coupling as a response to competing institutional logics. Academy of Management Journal, 56: 972–1001.\n\nPalich, L. E., & Bagby, D. R. 1995. Using cognitive theory to explain entrepreneurial risk-taking: Challenging conventional wisdom. Journal of Business Venturing, 10: 425– 438.\n\nPetty, R. E., Briñol, P., & DeMarree, K. G. 2007. The meta-cognitive model (MCM) of attitudes: Implications for attitude measurement, change, and strength. Social Cognition, 25: 657– 686.\n\nPfeffer, J., & Salancik, G. R. 1978. The external control of organizations: A resource dependence perspective. New York: Harper and Row.\n\nPlambeck, N., & Weber, K. 2009. CEO ambivalence and responses to strategic issues. Organization Science, 20: 993–1010.\n\nPlambeck, N., & Weber, K. 2010. When the glass is half full and half empty: CEOs’ ambivalent interpretations of strategic issues. Strategic Management Journal, 31: 689 – 710.\n\nPorac, J. F., & Rosa, J. A. 1996. In praise of managerial narrow-mindedness. Journal of Management Inquiry, 5: 35– 42.\n\nPorac, J. F., & Thomas, H. 2002. Managing cognition and strategy: Issues, trends and future directions. In A. M. Pettigrew, H. Thomas, & R. Whittington (Eds.), Handbook of strategy and management: 165–181. London & Thousand Oaks, CA: Sage.\n\nPrasad, P., & Elmes, M. 2005. In the name of the practical: Unearthing the hegemony of pragmatics in the discourse of environmental management. Journal of Management Studies, 42: 845– 867.\n\nPratt, M. G., & Foreman, P. O. 2000. Classifying managerial\n\n# Academy of Management Review\n\n# October\n\nresponses to multiple organizational identities. Academy of Management Review, 25: 18 – 42.\n\nPretty, J., Smith, G., Goulding, K. W. T., Groves, S. J., Henderson, I., Hine, R. E., King, V., van Oostrum, J., Pendlington, D. J., Vis, J. K., & Walter, C. 2008. Multi-year assessment of Unilever’s progress towards agricultural sustainability. I: Indicators, methodology and pilot farm results. International Journal of Agricultural Sustainability, 6: 37– 62.\n\nPugh, D. S., Hickson, D. J., Hinings, C. R., Macdonald, K. M., Turner, C., & Lupton, T. 1963. A conceptual scheme for organizational analysis. Administrative Science Quarterly, 8: 289 –315.\n\nPurdy, J. M., & Gray, B. 2009. Conflicting logics, mechanisms of diffusion, and multilevel dynamics in emerging institutional fields. Academy of Management Journal, 52: 355–380.\n\nReay, T., & Hinings, C. R. 2009. Managing the rivalry of competing institutional logics. Organization Studies, 30: 629 – 652.\n\nReinhardt, F. L., Stavins, R. N., & Vietor, R. H. K. 2008. Corporate social responsibility through an economic lens. Review of Environmental Economics and Policy, 2: 219 –239.\n\nRobinson, G., & Dechant, K. 1997. Building a business case for diversity. Academy of Management Executive, 11(3): 21–31.\n\nRosch, E. 1975. Cognitive reference points. Cognitive Psychology, 7: 532–547.\n\nRudolph, T. J., & Popp, E. 2007. An information processing theory of ambivalence. Political Psychology, 28: 563–585.\n\nSalzmann, O., Ionescu-Somers, A., & Steger, U. 2005. The business case for corporate sustainability: Literature review and research options. European Management Journal, 23: 27–36.\n\nSchwartz, M. S., & Carroll, A. B. 2008. Integrating and unifying competing and complementary frameworks. The search for a common core in the business and society field. Business & Society, 47: 148 –186.\n\nScott, W. A., Osgood, D. W., & Peterson, C. 1979. Cognitive structure: Theory and measurement of individual differences. New York: Wiley.\n\nSharma, S. 2000. Managerial interpretations and organizational context as predictors of corporate choice of environmental strategy. Academy of Management Journal, 43: 681– 697.\n\nSharma, S., Pablo, A. L., &"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 153, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197271, Requested 7178. Please try again in 1.334s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197271, Requested 7178. Please try again in 1.334s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "factors that drive corporate sustainability policy at the firm level have been highlighted as an important topic of research that requires additional attention (Dam and Scholtens, 2012; Aguilera et al., 2007). Undertaking such research in emerging economies has also been highlighted as necessary (Ziegler and Schröder, 2010). In this regard, this work intends to advance research in the emerging markets framework by studying Brazil, an emerging economy with increasing international visibility, characterized by high private benefits of control, high ownership concentration and low protection of minority shareholders which favors the prevalence of controlling shareholders’ interests (Dyck and Zingales, 2004; La Porta et al., 1998). Besides, Brazil has faced some institutional advances in environmental protection in recent decades although there is still much to be done (Tollefson, 2016).\n\nUnder the Brazilian environmental legislation, Law 10.165/2000 categorized industries’ environmental risk and enforced government environmental control. At this moment, it is important to assess whether these institutional advances observed in the Brazilian environmental legislation have been able to produce effects on the firm level.\n\nThis research aims to analyze firm’s attributes that are related to social and sustainability policies of Brazilian firms, focusing on firm’s environmental risk and ownership concentration. In this regard, more recently, ownership structure has been suggested to play a role on firm’s social and sustainability policies because of distinct shareholders’ interests and the diversity in institutional contexts (Dam and Scholtens, 2012; Aguilera et al., 2007; Li and Zhang, 2010), as well as the environmental risk of firm’s activities (Adams, 2002; Crifo et al., 2015; Hackston and Milne, 1996). Additionally, the study also searches for the effect of the financial crisis (2007-2009) on CSP and its eventual recovery in the aftermath.\n\nTo achieve this purpose, logistic regression models were estimated for a panel data set of 327 Brazilian listed firms, in a total of 2,685 firm-year observations, in the period of 2006-2015. The annual membership to the ISE of BM&FBOVESPA is used as proxy for higher CSP.\n\nThe results show that firm’s membership to an environmental risky industry, according the Brazilian environmental law, is able to improve firm’s CSP. In fact, firms from environmental risky industries are leading CSP firms in Brazil given that they present higher probability to be a component of the ISE sustainability index. The findings also indicate that CSP proxied by the membership to the ISE sustainability index is adversely affected by high ownership concentration. This reveals the presence of an agency conflict in which dominant shareholders’ interests prevail over CSP, given that the presence of such shareholders lowers the probability that the firm becomes member of the annual Brazilian ISE. It is worth\n\nmentioning that the negative effect of voting ownership concentration disappears with the presence of more large shareholders, taken into account by the voting ownership held by the four and five largest shareholders, signaling a possible contest power from other large shareholders who may favor CSR. Furthermore, other firm attributes also increase firm CSP, firm size and firm growth opportunities in Brazil.\n\nThe present work offers insights on the determinants of firm’s social and sustainability policies in an important emerging market (Brazil). The research builds on stakeholder and agency theories by investigating the possible effect of industry environmental risk and ownership concentration on CSP as proxied by firm’s membership to the Brazilian firm ISE. The study contributes to the literature that deals with firm membership to sustainability indices set by capital markets as a proxy for social and sustainability performance (Lourenc¸o and Castelo Branco, 2013; Crisostomo and Oliveira, 2016; Artiach et al., 2010). Specifically, the paper complements prior studies in the Brazilian market about CSP determinants by taking into account the industry environmental risk, using a larger variety of proxies for ownership concentration, extending the period of study and using panel data methodology that provides even more robust results and allows better analysis on the CSP determinants.\n\n# 2. Background and hypotheses\n\n# 2.1 The assessment of corporate sustainability\n\nLiterature suggests that firms actions related to sustainability are associated with ethical, environmental and economic criteria of a firm’s decision-making process to ensure business continuity, while corporate social policy may be more associated to the willingness of the firm to undertake actions that benefit stakeholders (Van Marrewijk and Werre, 2003). As a whole, corporate social and sustainability concerns integrate business ethics and stakeholder management, being all associated and complementary concepts under development (Sarkar and Searcy, 2016; Carroll and Shabana, 2010). Conceptual questions apart, assessing the degree of attention that a firm directs to social and sustainability concerns is a complex task and there is still no agreement on how it should be done. In fact, there are a variety of measures used in this context trying to adequately evaluate firm’s social and sustainability concerns (Griffin and Mahon, 1997; Orlitzky et al., 2003).\n\nThe assessment of CSP as a whole may take into account firm sustainability, firm social concerns, business ethics, stakeholder management and environmental issues. Specialized institutions have worked on it and created indices that intend to convey information about the level of firms’ CSP (Statman, 2006). Examples of such indices are the ones created by market institutions like the Dow Jones Sustainability Index of the New York Stock Exchange; the FTSE-4Good in the London Stock Exchange; the Johannesburg Index in South Africa; and the Brazilian ISE set up by the Brazilian stock market.\n\n# 2.2 The Brazilian corporate sustainability index\n\nThe ISE index is a theoretical portfolio, composed by up to 40 firms that are included into it based"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 125, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\graph\\graph_extractor.py\", line 164, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 196109, Requested 7781. Please try again in 1.167s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 196109, Requested 7781. Please try again in 1.167s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": {
        "doc_index": 0,
        "text": "has been left unturned” (Thomas et al., 1993: 243), they will have a high sense of mastery and control over sustainability issues.\n\nDecision makers assess issue valence by evaluating those aspects of an issue they have noticed against the categories of their cognitive frame (Petty, Briñol, & DeMarree, 2007). Rudolph and Popp (2007) found that individuals with strong directional goals tend to interpret issues univalently—that is, as either clearly positive or clearly negative. Because of the strong direction decision makers with a paradoxical frame will no-\n\n# Academy of Management Review\n\n# October\n\n# FIGURE 3\n\n# Effects of the Business Case Frame and the Paradoxical Frame on Issue Interpretation\n\n| |Paradoxical frame| |Business case frame| | | |\n|---|---|---|---|---|---|---|\n| |P4b|PSb|P6|PSa|P4a| |\n|Low|Moderate|High| | | | |\n\nDecision makers notice a wide range of aspects of a sustainability issue. This broad and inclusive approach will increase their sense of control over sustainability issues, since they believe they will not have missed any important dimension of the problem (Das & Teng, 1999). On the other hand, because of the more complex structure of their frame, decision makers will accept that there are tensions and conflicts between different economic, environmental, and social aspects that can never be fully resolved (Hahn, Pinkse, Preuss, & Figge, in press; Smith & Lewis, 2011). This heightened awareness of conflict will lower their sense of control over the issue (Das & Teng, 1999). Overall, then, we expect decision makers with a paradoxical frame to perceive a moderate sense of control over sustainability issues.\n\nThe greater diversity of the paradoxical frame also affects the valence of the evaluation of sustainability issues. “Ambivalent evaluations are likely to arise when executives examine more diverse aspects of an issue, which itself is in part driven by the [cognitive] frameworks employed in the process” (Plambeck & Weber, 2010: 692). Research in environmental psychology (Castro, Garrido, Reis, & Menezes, 2009; Costarelli & Colloca, 2004) shows that the multidimensionality of sustainability issues spurs ambivalent issue interpretations. For instance, domestic waste recycling has been found to simultaneously induce both positive evaluations and negative evaluations—for example, doubts about the overall effect of personal efforts when others do not recycle as well (Castro et al., 2009). With a very low sense of control, decision makers will perceive issues to be beyond their own influence, which will lead them to disengage from the issue and fall back on simpler univalent assessments. With a very high sense of control, decision makers will also evaluate issues univalently because they are overly confident that they can master an issue with existing resources.\n\nroutines and fail to consider alternatives (Miller, 1993). Overall, we expect managers with a paradoxical frame, and the resulting moderate sense of control, to experience enough control to handle diverse and competing aspects of an issue, but not enough control to rely excessively on routine evaluations. As a result, such managers will more likely apply distinct and competing positive and negative evaluations simultaneously (see Figure 3).\n\n# Proposition 4b:\n\nThe more paradoxical their cognitive frame, the more likely decision makers are to perceive a moderate sense of control over a wide range of sustainability issues and to interpret these issues ambivalently.\n\nSince managerial sensemaking of strategic issues is embedded in an organizational context, organizational identity has been suggested as a critical factor affecting interpretation (Bundy, Shropshire, & Buchholtz, 2013). Organizational identity represents the shared beliefs about the central, distinctive, and enduring features of an organization (Albert & Whetten, 1985). It guides and filters individuals’ interpretation of strategic issues, shaping the meanings given to an issue (Dutton & Dukerich, 1991; Walsh, 1995). Organizational identity defines what aspects decision makers see as positive or negative and what are seen as legitimate interpretations (Dutton & Dukerich, 1991). We therefore expect that the effects of the business case frame and the paradoxical frame on issue valence will be moderated by organizational identity.\n\nA homogeneous identity leads to a single uncontested conceptualization of what is central, distinctive, and enduring about the organization. With its strong self-reinforcing dynamic (Fiol, 2002), a homogeneous identity keeps organizational members focused on organizational goals (Pratt & Foreman, 2000). In the case of a unitary “business” identity (Albert & Whetten, 1985), the “competitive business model in which success is measured in terms of above-market returns and ever-increasing growth rates is more deeply ingrained in . . . beliefs and practices” (Hamilton & Gioia, 2009: 448). Decision makers are primed by such existing routines and are therefore less likely to integrate a diverse set of aspects in their interpretation of strategic issues (Plambeck & Weber, 2010). Ambivalent interpretations of sustainability issues that include nonbusiness aspects tend to be delegitimized. In contrast, a heterogeneous identity (Gioia, Schultz, & Corley, 2000; Pratt & Foreman, 2000) admits more diverse aspects and, thus, makes ambivalent evaluations more likely (Plambeck & Weber, 2010). Organizations with heterogeneous conceptualizations of their central, distinctive, and enduring features accommodate multiple interpretations (Gioia et al., 2000) and tend to have more complex relationships with a wide spectrum of external stakeholders (Brickson"
    }
}
{
    "type": "error",
    "data": "Community Report Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\community_reports\\community_reports_extractor.py\", line 57, in __call__\n    await self._llm(\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke_json(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 80, in _invoke_json\n    result = await generate()\n             ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 72, in generate\n    await self._native_json(input, **{**kwargs, \"name\": call_name})\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 96, in _native_json\n    result = await self._invoke(\n             ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197602, Requested 5470. Please try again in 921ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197602, Requested 5470. Please try again in 921ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": null
}
{
    "type": "error",
    "data": "Community Report Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\community_reports\\community_reports_extractor.py\", line 57, in __call__\n    await self._llm(\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke_json(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 80, in _invoke_json\n    result = await generate()\n             ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 72, in generate\n    await self._native_json(input, **{**kwargs, \"name\": call_name})\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 96, in _native_json\n    result = await self._invoke(\n             ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197013, Requested 5934. Please try again in 884ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197013, Requested 5934. Please try again in 884ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": null
}
{
    "type": "error",
    "data": "Community Report Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\community_reports\\community_reports_extractor.py\", line 57, in __call__\n    await self._llm(\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke_json(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 80, in _invoke_json\n    result = await generate()\n             ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 72, in generate\n    await self._native_json(input, **{**kwargs, \"name\": call_name})\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 96, in _native_json\n    result = await self._invoke(\n             ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 196092, Requested 7559. Please try again in 1.095s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 196092, Requested 7559. Please try again in 1.095s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": null
}
{
    "type": "error",
    "data": "Community Report Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\community_reports\\community_reports_extractor.py\", line 57, in __call__\n    await self._llm(\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke_json(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 80, in _invoke_json\n    result = await generate()\n             ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 72, in generate\n    await self._native_json(input, **{**kwargs, \"name\": call_name})\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 96, in _native_json\n    result = await self._invoke(\n             ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 195450, Requested 6183. Please try again in 489ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 195450, Requested 6183. Please try again in 489ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": null
}
{
    "type": "error",
    "data": "Community Report Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\community_reports\\community_reports_extractor.py\", line 57, in __call__\n    await self._llm(\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke_json(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 80, in _invoke_json\n    result = await generate()\n             ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 72, in generate\n    await self._native_json(input, **{**kwargs, \"name\": call_name})\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 96, in _native_json\n    result = await self._invoke(\n             ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 193984, Requested 7505. Please try again in 446ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 193984, Requested 7505. Please try again in 446ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": null
}
{
    "type": "error",
    "data": "Community Report Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\community_reports\\community_reports_extractor.py\", line 57, in __call__\n    await self._llm(\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke_json(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 80, in _invoke_json\n    result = await generate()\n             ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 72, in generate\n    await self._native_json(input, **{**kwargs, \"name\": call_name})\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 96, in _native_json\n    result = await self._invoke(\n             ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197800, Requested 6864. Please try again in 1.399s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197800, Requested 6864. Please try again in 1.399s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": null
}
{
    "type": "error",
    "data": "Community Report Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\community_reports\\community_reports_extractor.py\", line 57, in __call__\n    await self._llm(\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke_json(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 80, in _invoke_json\n    result = await generate()\n             ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 72, in generate\n    await self._native_json(input, **{**kwargs, \"name\": call_name})\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 96, in _native_json\n    result = await self._invoke(\n             ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194390, Requested 8172. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 194390, Requested 8172. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": null
}
{
    "type": "error",
    "data": "Community Report Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\index\\graph\\extractors\\community_reports\\community_reports_extractor.py\", line 57, in __call__\n    await self._llm(\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 418, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 185, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"E:\\Programing\\Python\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 151, in do_attempt\n    await sleep_for(sleep_time)\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 49, in __call__\n    return await self._invoke_json(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 80, in _invoke_json\n    result = await generate()\n             ^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 72, in generate\n    await self._native_json(input, **{**kwargs, \"name\": call_name})\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 96, in _native_json\n    result = await self._invoke(\n             ^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1843, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"e:\\Repositories\\graphrag-businessqa-evaluation\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1638, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197211, Requested 8232. Please try again in 1.632s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
    "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-IDSzXwOFLXiOywnvb6RkIg85 on tokens per min (TPM): Limit 200000, Used 197211, Requested 8232. Please try again in 1.632s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
    "details": null
}
